{
  "hash": "5293fa16be8bf535a9561ec024c3e2aa",
  "result": {
    "markdown": "---\ntitle: \"Como usar API do Twitter\"\nauthor: \"Jorge Luiz Mendes\"\neditor: visual\ndate: \"2022-10-10\"\ncategories: [api, seleção, twitter]\ndescription: \"Um tutorial básico de como acessar a API do Twitter para obter dados\"\nimage: \"image1.png\"\ndraft: false\ntoc: true\nbibliography: references.bib\n---\n\n\n## **Introdução**\n\n**API** ou interface de programação de aplicação é basicamente uma ferramenta que estabelece uma comunicação entre sistemas. Nela é possível que realizar troca de informações de forma segura utilizando diferentes linguagens de programação.\n\nO **Twitter** fornece API para consumo de dados para algumas lnguagem como **python**, **R**, entre outras. O **R** possui uma biblioteca específica para isso chamada ***rtweet*** [@rtweet].\n\n## **Primeiros passos...**\n\nInicialmente devesse criar uma conta no **Twitter** e em seguida criar uma conta de desenvolvedor na própria plataforma. Ao criar um projeto e um aplicativo serão geradas chaves de acesso para a requisição de dados via API.\n\n![Portal do Desenvolvedor](Conta_devl.png){fig-align=\"center\"}\n\n::: {.callout-note collapse=\"false\"}\n## Ao criar a conta lembre-se de ativar a autenticação em dois fatores.\n:::\n\n## **Bibliotecas**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"rtweet\")\n#install.packages(\"wordcloud\")\n#install.packages(\"tm\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(lubridate)\nlibrary(knitr)\nlibrary(rtweet)\nlibrary(wordcloud)\nlibrary(tm)\n```\n:::\n\n\nExistem 3 formas simples de se fazer a autenticação:\n\n::: panel-tabset\n## Usando as chaves\n\n::: panel-tabset\nNa função mencionada ***create_token*** basta inserir os argumentos fornecidos na hora de criar o app.\n\n-   app\n\n-   consumer key\n\n-   consumer secret\n\n-   access token\n\n-   access secret\n:::\n\n## Login\n\n::: panel-tabset\nCaso tenha algum tipo de problema com o primeiro método, é possível utilizar a mesma função ***create_token*** sem argumentos. Neste caso você será levado a uma página de login do Twitter e um código de autenticação será enviado um código para o seu celular.\n\n![](auth.png)\n:::\n\n## Usando rtweet app\n\n::: panel-tabset\nOutra opção é usar a função ***rtweet_app***, nesse caso uma tela e será necessário fornecer a Bearer token.\n\n![](rtweer_app_auth.png){fig-align=\"center\"}\n:::\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Escolha\n\nEu tive problemas com a primeiro e terceiro método de autenticação. Uma análise mais profunda da documentação do pacote possa revelar a solução mas na ausência de tempo escolhi o que funcionou sem ter nenhum erro.\n\nA função ***create_token*** foi descontinuada a partir da versão 1.0.0 do pacote rtweet e a função ***rtweet_app*** é mais indicada para versão 1.0.2 .\n:::\n\n::: {.callout-important collapse=\"true\"}\n## Cuidado!!! Sempre proteja suas chaves.\n\nEsse não é o caso mas existem API's que são pagas, além do prejuízo financeiro, a ideia de terceiros utilizarem para fins duvidosos já causa preocupação. Caso interesse em disponizibilizar seus scripts existem métodos seguros para proteger senhas e chaves, mas como não é o foco dessa postagem tem esse [blog](https://blog.curso-r.com/posts/2022-09-13-senha-no-script/).\n:::\n\n## Autenticando\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwitter_token = create_token()\nauth_as(twitter_token)\n```\n:::\n\n\n## Manipulações\n\nApós a autenticação podemos iniciar nossas análises .\n\nCom a função `search_tweets` ajuda a fazer busca por assuntos ou perfis. Podemos escolher o número de tweets, o idioma, entre outras opções.\n\nNesse caso trouxemos 3000 tweets com o assunto **seleção**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselecao <- search_tweets(\"seleção\", n=3000)\n```\n:::\n\n\nAntes de fazer visualizações devemos fazer uma limpeza nos dados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove retweets e replies\nselecao_tweets_organic <- selecao %>% filter(\n  retweeted == FALSE, is.na(in_reply_to_status_id)\n                                             ) \n# converte o tipo \nselecao_tweets_organic$full_text <- as.character(\n selecao_tweets_organic$full_text)\n\n#selecionar só as colunas que serão utilizadas\nselecao_tweets_organic <-selecao_tweets_organic %>% select(created_at,full_text,retweet_count,favorite_count,display_text_range,lang)\n\n# removendo palavras que não fazem sentido para análise\nselecao_tweets_organic$full_text <- gsub(\"com\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"que\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"pra\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"blimag\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"tô\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"por\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"bolsonaro\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"uma\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"Bolsonaro\",\"\",selecao_tweets_organic$full_text)\n```\n:::\n\n\nUma nuvem de palavras é um tipo de visualização muito boa para dados textuais e para executar essa tarefa temos a biblioteca `{wordcloud}` nela podemos passar uma coluna de dataframe como dado de entrada.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234) # reprodutibilidade\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwordcloud(selecao_tweets_organic$full_text, \n          min.freq=5, scale=c(3.5, .5), \n          random.order=FALSE, rot.per=0.45, \n          colors=brewer.pal(8, \"Dark2\"))\n```\n\n::: {.cell-output-display}\n![](API_Twitter_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nPodemos fazer análises com base no horário em que o tweet foi criado.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselecao_tweets_organic$hora_criada <-lubridate::hour(selecao_tweets_organic$created_at)\n```\n:::\n\n\nEm média qual horário teve mais Retweet, Favoritoe e Tamanho de Texto?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselecao_tweets_organic %>% group_by(hora_criada) %>%\n  summarise(round(mean(retweet_count)),\n            round(mean(favorite_count)),\n            round(mean(display_text_range))) %>% \n  kable(col.names = c(\"Hora\",\"Retweet\",\"Favorito\",\"Tamanho do Texto\"),caption = \"Médias Referentes ao Assunto Seleção\")\n```\n\n::: {.cell-output-display}\nTable: Médias Referentes ao Assunto Seleção\n\n| Hora| Retweet| Favorito| Tamanho do Texto|\n|----:|-------:|--------:|----------------:|\n|    0|     417|        0|              119|\n|    1|     173|        2|              133|\n|    2|      91|        1|              126|\n|    3|     169|        0|              131|\n|    4|     241|        1|              133|\n|    5|     123|        1|              124|\n|    6|     148|        1|              134|\n|    7|     124|       14|              138|\n|    8|     223|        3|              134|\n|    9|      87|       14|              139|\n|   10|      81|        6|              131|\n|   11|      91|       34|              129|\n|   12|     195|       44|              126|\n|   15|     176|     4846|              151|\n:::\n:::\n\n\nEscolhendo um perfil dessa vez. Aproveitando que é semana de champions escolhi o Vinícius Junior do Real Madrid.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvinijr <- search_tweets(\"@vinijr\", n = 3000)\n```\n:::\n\n\nQuais idiomas presentes nos tweets?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(vinijr$lang)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"und\" \"es\"  \"en\"  \"it\"  \"ht\"  \"fr\"  \"pt\"  \"in\"  \"cy\"  \"ar\"  \"ca\"  \"eu\" \n[13] \"fi\"  \"nl\"  \"tl\"  \"et\"  \"lv\"  \"no\"  \"tr\" \n```\n:::\n:::\n\n\nDesconsiderando o português qual a porcetagem de presença dos tweets?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvinijr %>% filter(lang != \"pt\") %>% \n  group_by(lang) %>% \n  summarise(contagem=n()) %>%\n  arrange(desc(contagem)) %>% \n  slice(1:5) %>%\n  mutate(\n    langEx = case_when(lang ==\"ar\"~\"Árabe\",\n                     lang ==\"es\"~\"Espanhol\",\n                     lang ==\"fr\"~\"Francês\",\n                     lang ==\"en\"~\"Inglês\", \n                     lang ==\"und\"~\"Não Detectado\",\n                     )) %>% \n   \n  mutate(Perc = round(contagem /sum(contagem)*100 ,2 )) %>% \n  ggplot(aes(x= langEx,y =Perc,label = Perc)) +\n  geom_col(fill =\"gray\") +\n    \n  geom_text(position = position_stack(vjust =1.05),\n           color=\"#030202\") +\n  labs(\n    title= \"Os 5 Idiomas mais Presentes nos Tweets do @vinijr\",\n       subtitle = \"Desconsiderando o Português\", x =\"\", \n       y ='Porcentagem (%)') +\n   theme(axis.ticks.x=element_blank(),\n          axis.text.y =element_blank())\n```\n\n::: {.cell-output-display}\n![](API_Twitter_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Conclusão\n\nEmbora eu tenha descartado a maioria das colunas, estou impressionado pelo volume de informação que a API disponibiliza para o usuário (43 colunas) um leque absurdo de análises que podem ser feitas. A parte mais complexa é estabelecer a conexão com a API mas uma vez feita basta se atentar no tempo de validade das chaves.\n\n## Ver Também\n\n-   [Céline Van den Rul](https://medium.com/@celine.vdr?source=post_page-----2f56818fdd16--------------------------------)\n",
    "supporting": [
      "API_Twitter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}