[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jorge L. Mendes",
    "section": "",
    "text": "Me chamo Jorge. Sou graduando em Engenharia Química pela Universidade Federal de São Paulo.\nComecei a ter afinidade pela linguagem R no final de 2020 e me apaixonei pelo RMarkdown/Quarto."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jorge Mendes",
    "section": "",
    "text": "api\n\n\nseleção\n\n\ntwitter\n\n\n\n\nUm tutorial básico de como acessar a API do Twitter para obter dados\n\n\n\n\n\n\nOct 10, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nsaneamento\n\n\ncsv\n\n\ngeobr\n\n\nggplot\n\n\n\n\nAtlas do Esgoto\n\n\n\n\n\n\nSep 10, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nfutebol\n\n\n\n\nAnalisando os resultados do campeonato brasileiro\n\n\n\n\n\n\nJul 14, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nANP\n\n\n\n\nPanorama a respeito do petróleo e biblioteca ggplot\n\n\n\n\n\n\nJul 4, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html",
    "href": "posts/Petroleum/Petroleum.html",
    "title": "Petróleo",
    "section": "",
    "text": "O petróleo é um recurso extremamente necessário, presente em diversos setores da economia (indústria, agricultura, combustíveis, e etc).\n\n\n\n\n\n[Link do Ícone](Barril de óleo ícones criados por mangsaabguru - Flaticon)"
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html#bibliotecas",
    "href": "posts/Petroleum/Petroleum.html#bibliotecas",
    "title": "Petróleo",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(tidyverse)\nlibrary(gghighlight)\nlibrary(magrittr)\nlibrary(plyr)\nlibrary(knitr)\nlibrary(geobr)\n\n\n\n\n\n\n\nE para que servem essas bibliotecas?\n\n\n\nO Tidyverse é um conjunto de bibliotecas muito útil que pode ser carregada rapidamente.\n\n\n\n\n\n\nreadr: Importar/Carregar dados;\ndplyr(tidyr, tibble, plyr): Manipulação e transformação de dados;\nggplot: Visualização de dados;\nmagrittr: Operador Pipe(“O velho %>%”) facilita a escrita do código. Também existe o novo pipe (“|>”) nativo nas versões atuais do RStudio;\nknitr: Ajuda a formatar tabelas."
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html#visão-geral",
    "href": "posts/Petroleum/Petroleum.html#visão-geral",
    "title": "Petróleo",
    "section": "Visão Geral",
    "text": "Visão Geral\nQuais países possuem as maiores reservas de petróleo?\nCarregando os dados.\n\nReserva_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-1.csv\")\n\nPlotando o Gráfico.\n\nReserva_internacional %>% filter(ANO ==2020) %>% \n  arrange(desc(`VALOR DA RESERVA`)) %>% slice(1:10) %>% \n    ggplot() +\n        aes(x =`VALOR DA RESERVA`,y =reorder(PAÍS,`VALOR DA RESERVA`),\n            fill = BLOCO,label =`VALOR DA RESERVA` ) +\n    geom_col() +\n          scale_fill_manual(values = c(\"orange\",\"seagreen3\")) +\n          labs(x =\"Bilhões de Barris\", y = \"\") +\n          \n          ggtitle(\"As 10 Maiores Reservas de Petróleo em 2020\") +\n          geom_label(size =3)\n\n\n\n\nA OPEP (Organização dos Países Exportadores de Petróleo) é uma organização que tem por objetivo regular a produção do petróleo para dar estabilidade no mercado internacionall.\nQuem são maiores produtores?\nCarregando os dados.\n\nProducao_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-2.csv\")\n\nPlotando o Gráfico.\n\n Producao_internacional %>% filter(ANO == 2020) %>% \n  arrange(desc(PRODUÇÃO)) %>% slice(1:10) %>%   \n  ggplot() +\n      aes(x =PRODUÇÃO ,y =reorder(PAÍS,PRODUÇÃO),fill=BLOCO, label = PRODUÇÃO) +\n        \n      geom_col() +\n           scale_fill_manual(values = c(\"orange\",\"seagreen3\")) +\n          labs(x =\"Milhares de Barris por Dia\", y = \"\") +\n          \n          ggtitle(\"Os 10 Maiores Produtores de Petróleo em 2020\") +\n          geom_label(size = 3)\n\n\n\n\nEmbora o Brasil não tenha as maiores reservas de petróleo, ele pertence ao grupo dos maiores produtores.\nAgora podemos analizar a produção anual de petróleo do Brasil.\n\n#Texto com quebra de linha\nTexto <- paste(\n  strwrap(\"Aumento da extração de petróleo do Pré-Sal no ano de 2015\",\n          20),\n  collapse = \"\\n\")\n\nProducao_internacional %>% filter(PAÍS ==\"Brasil\") %>% \n  ggplot() +\n   aes(x = ANO,y=PRODUÇÃO) +\n \n  geom_line(size =1.2,colour = \"grey\" ) +\n    scale_x_continuous(\n      breaks =c(2011,2012,2013,2014,2015,2016,2017,2018,2019,2020)) +\n  labs(y = \"Milhares de Barris por dia\") +\n  \n  geom_point(size = 3, colour = \"black\") +\n  \n  #Textos\n  annotate(\"text\",x = 2012 ,y =2800,size = 6,\n           label = \"BRASIL\", fontface = \"bold\",colour = \"green\") +\n  annotate(\"text\",x = 2018 ,y =2300,size = 5,\n           label = Texto, fontface = \"bold\",colour = \"red\") +\n   \n  #destacar um ponto\n  gghighlight(\n    ANO ==2015,\n    label_key = PRODUÇÃO,\n    #unhighlighted_colour = \"grey\",\n    label_params = list(size = 3.5,\n                        face = \"bold\",\n                        fill = \"red\"))\n\nWarning: Could not calculate the predicate for layer 3, layer 4; ignored\n\n\nWarning: Ignoring unknown parameters: face\n\n\n\n\n\nQuem foram os maiores consumidores em 2020?\nCarregando os dados.\n\nconsumo_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-3.csv\")\n\nUsando o pacote knitr para formatar tabelas.\n\nconsumo_internacional %>% \n  filter(ANO ==2020) %>% select(2:3) %>%  \n  arrange(desc(`CONSUMO DE PETRÓLEO`)) %>% slice(1:10) %>% \n  head(10) %>% \n  knitr::kable(col.names = c(\"País\",\"Consumo de Petróleo (mil barris por dia)\"))\n\n\n\n\nPaís\nConsumo de Petróleo (mil barris por dia)\n\n\n\n\nEstados Unidos\n17178\n\n\nChina\n14225\n\n\nÍndia\n4669\n\n\nArábia Saudita\n3544\n\n\nJapão\n3268\n\n\nRússia\n3238\n\n\nCoreia do Sul\n2560\n\n\nBrasil\n2323\n\n\nCanadá\n2282\n\n\nAlemanha\n2045\n\n\n\n\n\nE no Brasil? Quais estados tem reserva de petróleo?\nCarregando dados\n\nBr_Reservas <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-2-industria-nacional-do-petroleo-e-do-gas-natural/dados-abertos-csv/anuario-2021-dados_abertos-tabela2-3.csv\")\n\nAqui iremos somar as reservas marítimas e terrestres.\n\n#Vamos agrupar total das reservas(terra e mar)\nTotal_estados <- Br_Reservas %>% filter(ANO == 2020) %>% \n  group_by(`UNIDADES DA FEDERAÇÃO`) %>% \n  dplyr::summarise(\n    sum(\n      Total =`RESERVAS TOTAIS DE PETRÓLEO (EM MILHÕES DE BARRIS)`),\n      Count= n()\n    ) %>% \n  #renomeando as colunas\n  plyr::rename(replace =c(\"sum(Total = `RESERVAS TOTAIS DE PETRÓLEO (EM MILHÕES DE BARRIS)`)\"=\"Total\",\"UNIDADES DA FEDERAÇÃO\" = \"name_state\"))\n #Renomeando alguns itens\nTotal_estados$name_state[Total_estados$name_state ==\"Paraná5\"] <- \"Paraná\"\nTotal_estados$name_state[Total_estados$name_state ==\"Rio de Janeiro3\"] <- \"Rio De Janeiro\"\nTotal_estados$name_state[Total_estados$name_state ==\"Santa Catarina6\"] <- \"Santa Catarina\"\nTotal_estados$name_state[Total_estados$name_state ==\"São Paulo4\"] <- \"São Paulo\"\nTotal_estados$name_state[Total_estados$name_state ==\"Rio Grande do Norte\"] <- \"Rio Grande Do Norte\"\n#Formatando a tabela\nTotal <-Total_estados %>% \n  select(1:2) %>% kable(col.names = c(\"UF\",\"Total\"))\n\nTotal\n\n\n\n\nUF\nTotal\n\n\n\n\nAlagoas\n4.040435e+00\n\n\nAmazonas\n5.153600e+01\n\n\nBahia\n2.938644e+02\n\n\nCeará\n2.428873e-01\n\n\nEspírito Santo\n1.314880e+03\n\n\nMaranhão\n2.139806e-01\n\n\nParaná\n0.000000e+00\n\n\nRio De Janeiro\n1.603287e+04\n\n\nRio Grande Do Norte\n2.662763e+02\n\n\nSanta Catarina\n0.000000e+00\n\n\nSão Paulo\n2.079593e+03\n\n\nSergipe\n1.947730e+02\n\n\n\n\n\nPodemos apresentar os resultado na forma de mapa\nA biblioteca geobr nos force uma malha de pontos que podemos usar para construir mapas.\nCarregando os dados de 2017.\n\nMapa <-geobr::read_state(year = 2017)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |======================================================================| 100%\n\n\nAgora podemos unir as tabelas\n\n# um pequeno malabarismo para plotar o mapa completo\nv1 <-c(\"Rio Grande Do Sul\",\"Minas Gerais\",\"Mato Grosso Do Sul\",\n       \"Mato Grosso\",\"Goiás\",\"Distrito Federal\",\"Piauí\",\"Paraíba\",\n       \"Pernambuco\",\"Rondônia\",\"Acre\",\"Roraima\",\"Pará\",\"Amapá\",\n       \"Tocantins\")\nv2 <-rep(0,15)\n# selecionar as colunas de interesse\nTotal_estados <- Total_estados %>% select(1:2)\n\n#adicionando linhas ao dataframe\nlinhas <-data.frame(name_state =v1,Total = v2)\n\nTotal_estados <- rbind(Total_estados,linhas)\n\n#Finalmente unindo as tabelas \nEstados <- merge(Mapa, Total_estados, by = c(\"name_state\"))\n\nPlotando o Gráfico.\n\n  Estados %>% ggplot() +\n    geom_sf(aes(fill=Total), color= \"black\", size=.15) +\n      labs(subtitle=\"Reservas Totais Estimadas em 2020\", size=8) +\n      scale_fill_distiller(palette = \"Oranges\",direction=1, \n                           name=\"Milhões de Barris\") +\n      theme_minimal()"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html",
    "href": "posts/Campeonato Brasileiro/Br.html",
    "title": "Campeonato Brasileiro",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html#pay-attention",
    "href": "posts/Campeonato Brasileiro/Br.html#pay-attention",
    "title": "Campeonato Brasileiro",
    "section": "Pay Attention",
    "text": "Pay Attention\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n:::\n```"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html#including-plots",
    "href": "posts/Campeonato Brasileiro/Br.html#including-plots",
    "title": "Campeonato Brasileiro",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html",
    "title": "Campeonato Brasileiro",
    "section": "",
    "text": "Atualizado em 11/09/2022"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html",
    "href": "posts/Saneamento/Saneamento.html",
    "title": "Saneamento no Estado de São Paulo",
    "section": "",
    "text": "Saneamento é um tema de extrema importâcia. Aqui o foco principal é fazer uma análise exploratória simples com dados públicos."
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#bibliotecas",
    "href": "posts/Saneamento/Saneamento.html#bibliotecas",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(geobr)\nlibrary(ggspatial)\nlibrary(sf)"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#os-dados",
    "href": "posts/Saneamento/Saneamento.html#os-dados",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Os dados",
    "text": "Os dados\n\nOs dados foram obtidos da agência nacional de águas e saneamento básico ANA.\nFoi utilizado o Atlas Esgotos Situação 2013 - Remoção da Carga de Esgotos Gerada na Sede Municipal e o pacote geobr (Pereira and Goncalves 2021) para acessar informações sobre os dados espaciais do Brasil.\n\ndados <- readr::read_delim(\"Atlas_Esgoto2013.csv\",delim = ',')\n\n\nglimpse(dados)\n\nRows: 5,570\nColumns: 14\n$ FID        <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1~\n$ MUN_CD_MUN <dbl> 1100015, 1100023, 1100031, 1100049, 1100056, 1100064, 11000~\n$ MUN_NM_MUN <chr> \"Alta Floresta D Oeste\", \"Ariquemes\", \"Cabixi\", \"Cacoal\", \"~\n$ MUN_UF     <chr> \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\",~\n$ MUN_NM_PRE <chr> \"Serviço Autônomo de Água e Esgoto\", \"Companhia de Águas e ~\n$ MUN_SIGLA_ <chr> \"SAAE\", \"CAERD\", \"PM\", \"SAAE\", \"PM\", \"PM\", \"PM\", \"PM\", \"PM\"~\n$ MUN_POPU_2 <dbl> 14735, 85770, 2771, 67665, 15276, 14097, 2665, 8689, 22741,~\n$ MUN_ICS    <dbl> 1.4244810, 2.0176413, 0.3713331, 0.0000000, 0.6727235, 1.02~\n$ MUN_IFSUTI <dbl> 1.8468146, 8.5762823, 0.6312662, 16.1786793, 19.6892988, 4.~\n$ MUN_ISCST  <dbl> 96.728704, 89.406076, 98.997401, 28.821321, 79.637978, 94.9~\n$ MUN_C_GERA <dbl> 795, 4631, 149, 3653, 824, 761, 143, 469, 1228, 2088, 2027,~\n$ MUN_C_REMA <dbl> 786, 4393, 149, 1791, 727, 742, 138, 445, 1126, 1907, 1986,~\n$ MUN_EFIC_1 <dbl> 1.1080888, 5.1457694, 0.3787597, 50.9572076, 11.8135793, 2.~\n$ MUN_ICT_FI <dbl> 0.000000, 0.000000, 0.000000, 55.000000, 0.000000, 0.000000~"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#manipulando-as-bases",
    "href": "posts/Saneamento/Saneamento.html#manipulando-as-bases",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Manipulando as Bases",
    "text": "Manipulando as Bases\nRenomeando as colunas (consultei o aplicativo do ANA).\n\ndados <- dados %>% \n    dplyr::rename( \n        c(\"code_muni\" = \"MUN_CD_MUN\",\"municipio\"=\"MUN_NM_MUN\" ,\n          \"uf\"=\"MUN_UF\", \"prestador_servico\"= \"MUN_NM_PRE\" ,\n          \"sigla_prestador\"=\"MUN_SIGLA_\"  ,\n          \"populacao2013\" =\"MUN_POPU_2\" , \n                \n          \"Parcela_População_Com_Coleta_Sem_Tratamento(%)\")= =\n            \"MUN_ICS\",\n                \n          \"Parcela_População_Com_Solução_Individual(%)\"(=)\" =\n            \"MUN_IFSUTI\" ,\n                \n          \"Parcela_População_Sem_Coleta_Sem_Tratamento(%)\")= =\n            \"MUN_ISCST\",\n                \n          \"Parcela_População_Com_Coleta_Com_Tratamento(%)\")= =\n            \"MUN_ICT_FI\",\n                \n          \"Carga_Gerada\"= \"MUN_C_GERA\",\n          \"Carga_Remanescente\" =\"MUN_C_REMA\"  ,\n          \"Remoção_Carga_Orgânica(DBO)(%)\"=\"MUN_EFIC_1\"))\"))\n\nPodemos gerar tabelas com o pacote knitr para gerar tabelas.\nQuais cidades geram maior carga de esgoto no estado de são paulo?\n\ndados %>% filter(uf == \"SP\") %>% \n  select(c(\"municipio\",\"Carga_Gerada\")) %>% \n  arrange(desc(Carga_Gerada)) %>% \n  slice(1:10) %>% \n  knitr::kable(col.names = \n                 c(\"Municípios\"\"\"Carga Gerada Total (kgDBO/dia)\")),\n               \"simple\",caption = \"Estado de São Paulo\"))\n\n\nEstado de São Paulo\n\nMunicípios\nCarga Gerada Total (kgDBO/dia)\n\n\n\nSão Paulo\n604822\n\n\nGuarulhos\n65986\n\n\nCampinas\n57323\n\n\nSão Bernardo do Campo\n43263\n\n\nOsasco\n40435\n\n\nSanto André\n38211\n\n\nSão José dos Campos\n35351\n\n\nRibeirão Preto\n32560\n\n\nSorocaba\n31355\n\n\nSantos\n22833\n\n\n\n\n\nCarregando os dados do geobr para o estado de São Paulo.\n\nmapa <- geobr::read_municipality(code_muni = 35,year = 2018)\n\nUsing year 2018\n\n\nUnindo as tabelas\n\nsp <- dados %>% filter(uf ==\"SP\") %>% merge(mapa)\nnrow(sp) # verificando se possui as 645 cidades do estado de sp\n\n[1] 645\n\n\nAgora podemos gerar mapas com os pontos geom.\nQuais cidades geram mais carga de esgoto no estado de São Paulo?\n\nsp  %>% ggplot() +\n  geom_sf(aes(fill = Carga_Gerada, geometry = geom)) + \n  labs(title = \"Situação do Estado de São Paulo\"lo\",\n       subtitle = \"Carga Total Gerada 2013\") +\n  scale_fill_distiller(palette = \"Reds\",direction = 1,\n                       name= \"KgDBO/dia\") +\n  theme(axis.title=element_blank(),\n                   axis.text=element_blank(),\n                   axis.ticks=element_blank())\n\n\n\n\nPodemos verificar uma região específica ( como um conjunto de cidades). A forma mais segura é utilizar os códigos dos municípios, algumas cidades compartilham o mesmo nome.\nQual a porcentagem da população com coleta e tratamento de esgoto na região do grande ABC?\nAproveitei e adicionei o nome dos municípios, eixos das coordenadas, escala e a indicação do norte.\n\nlistaABC = list(3548708, 3547809, 3529401, 3513801, 3548807, 3543303, 3544103)\n\nsp %>%  filter(code_muni %in% listaABC) %>%\n  ggplot() + \n  geom_sf(aes(fill = `Parcela_População_Com_Coleta_Com_Tratamento(%)`)`,\n              geometry = geom)) +\n  \n  geom_sf_label(aes(label = municipio,geometry =geom),\n                label.padding = unit(0.5,\"mm\"),\n                size = 2) +\n  \n  \n  labs(title = \"Parcela da População Com Coleta e Com Tratamento\"o\",\n       subtitle = \"Região do Grande ABC, 2013 \"\",\n       x = \"Longitude\",y =\"Latitude\") +\n  \n  scale_fill_distiller(palette = \"Greens\",direction = 1,\n                       name= \"(%)\") +\n  annotation_north_arrow(location = \"br\") +\n  annotation_scale(location =\"bl\"\n                   )\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#referências",
    "href": "posts/Saneamento/Saneamento.html#referências",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Referências",
    "text": "Referências\n\nBea Milz"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#ver-também",
    "href": "posts/Saneamento/Saneamento.html#ver-também",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Ver também",
    "text": "Ver também\n\nBea Milz"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#objetivo",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#objetivo",
    "title": "Campeonato Brasileiro",
    "section": "Objetivo",
    "text": "Objetivo\nExplorar a biblioteca brasileirão (Amorim 2022) . É uma boa base para praticar, principalmente, manipulações de dataframe.\nEla consegue, além de outras coisas, retornar jogos, a data, o placar e os clubes envolvidos desde 2003 no campeonato brasileiro de futebol."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#bibliotecas",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#bibliotecas",
    "title": "Campeonato Brasileiro",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(dplyr) #tratamento de dados\nlibrary(tidyr) #tratamento de dados\n\nlibrary(magrittr) #o pipe antigo\nlibrary(purrr) #programação funcionalal\nlibrary(lubridate) #tratar datas\nlibrary(knitr) #formatação de tabelasas\n\nlibrary(brasileirao) #base de dados utilizados\n\nlibrary(ggplot2) #gráficoss\nlibrary(treemap) #gráficoss\n\nlibrary(jpeg) #adicionar imagens\nlibrary(patchwork)  #adicionar imagens"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#mão-na-massa",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#mão-na-massa",
    "title": "Campeonato Brasileiro",
    "section": "Mão na Massa",
    "text": "Mão na Massa\nCarregando dados.\n\nBr <- brasileirao::matches\n\nPodemos expor os resultados na forma de tabela.\n\nknitr::kable(head(Br),align = \"lccrr\")\n\n\n\nseason\ndate\nhome\nscore\naway\n\n\n\n2003\n2003-03-29\nAthletico PR\n2x0\nGrêmio\n\n\n2003\n2003-03-29\nGuarani\n4x2\nVasco\n\n\n2003\n2003-03-30\nCorinthians\n0x3\nAtlético MG\n\n\n2003\n2003-03-30\nGoiás\n2x2\nPaysandu\n\n\n2003\n2003-03-30\nCriciúma\n2x0\nFluminense\n\n\n2003\n2003-03-30\nCruzeiro\n2x2\nSão Caetano\n\n\n\n\n\nVerificando os tipos de variáveis das colunas.\n\nglimpse(Br)\n\nRows: 8,026\nColumns: 5\n$ season <dbl> 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 200~\n$ date   <date> 2003-03-29, 2003-03-29, 2003-03-30, 2003-03-30, 2003-03-30, 20~\n$ home   <chr> \"Athletico PR\", \"Guarani\", \"Corinthians\", \"Goiás\", \"Criciúma\", ~\n$ score  <chr> \"2x0\", \"4x2\", \"0x3\", \"2x2\", \"2x0\", \"2x2\", \"1x1\", \"0x0\", \"1x1\", ~\n$ away   <chr> \"Grêmio\", \"Vasco\", \"Atlético MG\", \"Paysandu\", \"Fluminense\", \"Sã~\n\n\nRealizando algumas manipulações para obter resultados dos jogos a partir de 2010.\n\nTabela_extendida <- Br  %>% filter(season >=2010)  %>% \n  separate(score,\n           c(\"Placar_Mandante\",\"Placar_Visitante\"),\n           sep = \"x\",\n           convert = TRUE,\n           remove = FALSE\n    \n  ) %>% \n  mutate(\n    Mandante = case_when(\n      Placar_Mandante > Placar_Visitante~\"Venceu\",\n      Placar_Mandante < Placar_Visitante~\"Perdeu\",\n      Placar_Mandante == Placar_Visitante~\"Empate\"\n    ),\n     Visitante = case_when(\n      Placar_Mandante < Placar_Visitante~\"Venceu\",\n      Placar_Mandante > Placar_Visitante~\"Perdeu\",\n      Placar_Mandante == Placar_Visitante~\"Empate\"\n    )\n  )\n\nA ideia aqui é selecionar um clube e fazer as análises a partir dessa escolha. Vamos criar uma função para selecionar um time.\n\nClube<-function(dataframe,Time){\n  #selecionar o clube quando ele é mandantee\n        TimeMandante <-dataframe %>% filter(home==Time) %>% \n            select(season,date,home,Placar_Mandante,\n            Placar_Visitante,Mandante,away) %>% \n            rename(\n                    \"clube\"=\"home\",\n                    \"Gols_Pro\"=\"Placar_Mandante\",\n                    \"Gols_Contra\"=\"Placar_Visitante\",\n                    \"Resultado\"=\"Mandante\",\n                    \"adversario\" =\"away\") %>% \n            mutate(mando = \"Mandante\")\n  \n  #selecionar o clube quando ele é visitantee\n        TimeVisitante <- dataframe %>% \n            filter(away==Time) %>% \n            select(season,date,away,Placar_Visitante,\n            Placar_Mandante,Visitante,home) %>% \n            rename(\n                    \"clube\"=\"away\",\n                    \"Gols_Pro\"=\"Placar_Visitante\",\n                    \"Gols_Contra\"=\"Placar_Mandante\",\n                    \"Resultado\"=\"Visitante\",\n                     \"adversario\"=\"home\") %>% \n            mutate(mando = \"Visitante\")\n  \n  #Unindo as tabelas\n        Resultados <-rbind(TimeMandante,TimeVisitante)\n  \n  return(Resultados)\n  \n}\n\nSelecionando um time.\nO interessante é selecionar um clube que jogou muitas edições para ter uma boa quantidade de dados. Convenientemente foi selecionado o Corinthians.\n\n\n\n\n\nTimao<-Clube(dataframe= Tabela_extendida,Time =\"Corinthians\")\n\nÉ interessante adicionar os pontos obtidos em cada partida.\n\nTimao <- Timao %>% mutate(\n  Pontos = case_when(\n  Resultado ==\"Venceu\"~3,\n  Resultado ==\"Empate\"~1,\n  Resultado ==\"Perdeu\"~0,\n))\n\nUsando o pacote lubridate é possível tratar datas, obtendo informações sobre o dia,dia da semana, mês e ano de forma isolada.\n\n#Timao$dia_Mes <- lubridate::day(Timao$date)\nTimao$Mes <- lubridate::month(Timao$date, label = TRUE)\n#Timao$NdiaSemana <- lubridate::wday(Timao$date)\n\nQual o número de vitórias, empates e derrotas da última década?\n\nTimao %>% filter(!is.na(Pontos)) %>% count(Resultado) %>%  \n  treemap(index = c(\"n\",\"Resultado\"),\n          vSize = \"n\",\n          align.labels=list(c(\"center\", \"center\"),c(\"center\", \"top\")),\n          title = \"Resultados do Corinthians desde 2010\",\n          fontsize.labels=c(15,12),\n          palette = c(\"#cfc6c6\",\"#3d3a3a\",\"#0a0a0a\")\n           \n           )\n\n\n\n\nCom a função group_by e summarise podemos agrupar os dados.\n\nDadosAgg <- Timao %>% \n\n  filter(!is.na(Pontos)) %>% \n\n  group_by(Mes)%>% \n\n  summarise(\n\n    MediaPontos = round(mean(Pontos),2),\n    GolsPro = sum(Gols_Pro),\n    GolsContra =sum(Gols_Contra)) %>%\n\n    arrange(desc(Mes))\n\nDadosAgg %>% knitr::kable(col.names =\n                            c(\"Mês\"\"\"Pontos\"\"\"Gols Pro\"\"\"Gols Contra\")))\n\n\n\nMês\nPontos\nGols Pro\nGols Contra\n\n\n\ndez\n1.11\n16\n19\n\n\nnov\n1.82\n85\n58\n\n\nout\n1.40\n87\n80\n\n\nset\n1.37\n89\n77\n\n\nago\n1.56\n88\n69\n\n\njul\n2.00\n81\n35\n\n\njun\n1.71\n62\n38\n\n\nmai\n1.84\n53\n32\n\n\nabr\n1.78\n16\n9\n\n\nfev\n1.00\n6\n7\n\n\njan\n1.20\n9\n8\n\n\n\n\n\nQual mês, em média, fez mais pontos?\n\n DadosAgg%>% \n    \n    \n    ggplot(aes(x =MediaPontos ,y =Mes, label = MediaPontos)) +\n\n    geom_col(fill = \"gray\")+\n\n     \n    geom_text(\n            position = position_stack(vjust =1.05),\n            color=\"#030202\") +\n    \n    labs(x = \"Pontos\",y = \"Mês\"\", title==\"Média de Pontos em Cada Mês\"ªs\",\n         subtitle = \"valores a partir de 2010\") +\n    theme(axis.text.x = element_blank(),axis.ticks.x=element_blank(),\n          axis.text.y =element_text(face =\"bold\",\n                                    colour = \"#030202\"))\n\n\n\n\nEm quais mêses, fez e tomou ,mais gols?\n\nDadosAgg %>%  ggplot() +\n    \n    geom_col(aes(x = -GolsPro ,y =Mes), fill=\"#424d6b\") +\n\n     \n    geom_text(aes(x = -GolsPro ,y =Mes,label =GolsPro),\n            position = position_stack(vjust =0.5),\n            color =\"#ced2de\") +\n    \n    geom_col(aes(x = GolsContra,y =Mes), \n              fill=\"#806630\") +\n\n     \n    geom_text(aes(x =GolsContra ,y =Mes,label =GolsContra),\n            position = position_stack(vjust =0.5),\n            color=\"#030202\") +\n   annotate(\"text\",x = -50 ,y =2,label =\"Gols Pro\",\n            color =\"#424d6b\") +\n   annotate(\"text\",x = 50 ,y =2,label =\"Gols Contra\",\n            color =\"#806630\") +\n    \n    \n    labs(x = \"Gols\",y = \"Mês\"\", title==\"Total de Gols por Mês\"s\",\n         subtitle = \"valores a partir de 2010\") +\n    theme(axis.text.x = element_blank(),\n          axis.ticks.x=element_blank(),\n          axis.text.y =element_text(face =\"bold\",\n                                    colour = \"#030202\"))\n\n\n\n\nQual o desempenho das últimas temporadas?\n\nano <- c(2011,2015,2017)\npontuacao <-\n  Timao %>% filter(!is.na(Pontos)) %>% \n  group_by(season) %>% \n  summarise(Pontos = sum(Pontos)) %>% \n  mutate(Titulo = ifelse(season %in% ano, \"Campeão\"\",\"Não Ganhou\")))) \n\n\nTexto <- paste(\n  strwrap(\"A temporada de 2022 ainda não foi concluída\"a\",\n          20),\n  collapse = \"\\n\")\n\npath <-\"escudo1.jpg\"\nimg <- readJPEG(path,native = TRUE)\n\n\npontuacao %>% \n  ggplot() +\n    geom_line(aes(x = season, y = Pontos),size =1.4,colour =\"grey\") +\n    scale_x_continuous(breaks = c(2010:2022)) +\n    geom_point(aes(x = season, y = Pontos),size = 2,color=\"grey\") +\n    \n    geom_point(\n      aes(x = season,y=Pontos, color =Titulo, size= Titulo)) +\n    \n    scale_colour_manual(values = c(\"#0a0a0a\",\"#b3a6a6\")) +\n\n    scale_size_manual(values = c(3,2)) +\n    \n    geom_line(aes(x = c(2010:2022),y = mean(`Pontos`)),\n              linetype =2) +  \n  \n    labs(x =\"Temporada\",title = \"Desempenho do Clube\") +\n    \n    theme(axis.text.x = element_text(angle = 90)) +\n    \n    annotate(\"text\",x = 2011 ,y =60,size = 2,\n           label = \"Média\"\", fontface==\"bold\"\",colour==\"black\"))++\n    annotate(\"text\",x = 2018 ,y =35,size = 4,\n           label = Texto, fontface = \"bold\",colour = \"red\") +\n    inset_element(p = img,\n                left = 1.00,\n                bottom = 0.65,\n                right = 1.35,\n                top = 1.15)"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#conclusão",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#conclusão",
    "title": "Campeonato Brasileiro",
    "section": "Conclusão",
    "text": "Conclusão\nA biblioteca brasileirao é excelente . Foi possível extrair bastante informação. Ela fornece de forma simples os dados gerais sobre as partidas, infelizmente ela não trás informações como número de cartões, tempo de jogo sem interrupções, posse bola, e entre outras. Não é terra arrasada, pois outros dados de fontes distintas podem ser adicionados para complementar as análises."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#ver-também",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#ver-também",
    "title": "Campeonato Brasileiro",
    "section": "Ver também",
    "text": "Ver também\n\nr - graph - gallery\nBlog Curso -R"
  },
  {
    "objectID": "posts/Premier League/Premier League.html",
    "href": "posts/Premier League/Premier League.html",
    "title": "Premier League",
    "section": "",
    "text": "a <- c(0:40)\n print(a)\n##  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n## [26] 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html",
    "href": "posts/Twitter/API_Twitter.html",
    "title": "Como usar API do Twitter",
    "section": "",
    "text": "API ou interface de programação de aplicação é basicamente uma ferramenta que estabelece uma comunicação entre sistemas. Nela é possível que realizar troca de informações de forma segura utilizando diferentes linguagens de programação.\nO Twitter fornece API para consumo de dados para algumas lnguagem como python, R, entre outras. O R possui uma biblioteca específica para isso chamada rtweet (Kearney 2019)."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#primeiros-passos",
    "href": "posts/Twitter/API_Twitter.html#primeiros-passos",
    "title": "Como usar API do Twitter",
    "section": "Primeiros passos…",
    "text": "Primeiros passos…\nInicialmente devesse criar uma conta no Twitter e em seguida criar uma conta de desenvolvedor na própria plataforma. Ao criar um projeto e um aplicativo serão geradas chaves de acesso para a requisição de dados via API.\n\n\nPortal do Desenvolvedor\n\n\n\n\n\n\n\n\nAo criar a conta lembre-se de ativar a autenticação em dois fatores."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#bibliotecas",
    "href": "posts/Twitter/API_Twitter.html#bibliotecas",
    "title": "Como usar API do Twitter",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\n#install.packages(\"rtweet\")\n#install.packages(\"wordcloud\")\n#install.packages(\"tm\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(lubridate)\nlibrary(knitr)\nlibrary(rtweet)\nlibrary(wordcloud)\nlibrary(tm)\n\nExistem 3 formas simples de se fazer a autenticação:\n\n\nUsando as chaves\nLogin\nUsando rtweet app\n\n\n\n\nNa função mencionada create_token basta inserir os argumentos fornecidos na hora de criar o app.\n\napp\nconsumer key\nconsumer secret\naccess token\naccess secret\n\n\n\n\n\nCaso tenha algum tipo de problema com o primeiro método, é possível utilizar a mesma função create_token sem argumentos. Neste caso você será levado a uma página de login do Twitter e um código de autenticação será enviado um código para o seu celular.\n\n\n\n\n\nOutra opção é usar a função rtweet_app, nesse caso uma tela e será necessário fornecer a Bearer token.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscolha\n\n\n\n\n\nEu tive problemas com a primeiro e terceiro método de autenticação. Uma análise mais profunda da documentação do pacote possa revelar a solução mas na ausência de tempo escolhi o que funcionou sem ter nenhum erro.\nA função create_token foi descontinuada a partir da versão 1.0.0 do pacote rtweet e a função rtweet_app é mais indicada para versão 1.0.2 .\n\n\n\n\n\n\n\n\n\nCuidado!!! Sempre proteja suas chaves.\n\n\n\n\n\nEsse não é o caso mas existem API’s que são pagas, além do prejuízo financeiro, a ideia de terceiros utilizarem para fins duvidosos já causa preocupação. Caso interesse em disponizibilizar seus scripts existem métodos seguros para proteger senhas e chaves, mas como não é o foco dessa postagem tem esse blog."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#ver-também",
    "href": "posts/Twitter/API_Twitter.html#ver-também",
    "title": "Como usar API do Twitter",
    "section": "Ver Também",
    "text": "Ver Também\n\nCéline Van den Rul"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#manipulações",
    "href": "posts/Twitter/API_Twitter.html#manipulações",
    "title": "Como usar API do Twitter",
    "section": "Manipulações",
    "text": "Manipulações\nApós a autenticação podemos iniciar nossas análises .\nCom a função search_tweets ajuda a fazer busca por assuntos ou perfis. Podemos escolher o número de tweets, o idioma, entre outras opções.\nNesse caso trouxemos 3000 tweets com o assunto seleção.\n\nselecao <- search_tweets(\"seleção\", n=3000)\n\nAntes de fazer visualizações devemos fazer uma limpeza nos dados.\n\n# Remove retweets e replies\nselecao_tweets_organic <- selecao %>% filter(\n  retweeted == FALSE, is.na(in_reply_to_status_id)\n                                             ) \n# converte o tipo \nselecao_tweets_organic$full_text <- as.character(\n selecao_tweets_organic$full_text)\n\n#selecionar só as colunas que serão utilizadasas\nselecao_tweets_organic <-selecao_tweets_organic %>% select(created_at,full_text,retweet_count,favorite_count,display_text_range,lang)\n\n# removendo palavras que não fazem sentido para análisese\nselecao_tweets_organic$full_text <- gsub(\"com\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"que\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"pra\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"blimag\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"tô\"\"\"\"\"selecao_tweets_organic$full_text))\nselecao_tweets_organic$full_text <- gsub(\"por\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"bolsonaro\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"uma\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"Bolsonaro\",\"\",selecao_tweets_organic$full_text)\n\nUma nuvem de palavras é um tipo de visualização muito boa para dados textuais e para executar essa tarefa temos a biblioteca wordcloud nela podemos passar uma coluna de dataframe como dado de entrada.\n\nset.seed(1234) # reprodutibilidade\n\n\nwordcloud(selecao_tweets_organic$full_text, \n          min.freq=5, scale=c(3.5, .5), \n          random.order=FALSE, rot.per=0.45, \n          colors=brewer.pal(8, \"Dark2\"))\n\n\n\n\nPodemos fazer análises com base no horário em que o tweet foi criado.\n\nselecao_tweets_organic$hora_criada <-lubridate::hour(selecao_tweets_organic$created_at)\n\nEm média qual horário teve mais Retweet, Favoritoe e Tamanho de Texto?\n\nselecao_tweets_organic %>% group_by(hora_criada) %>%\n  summarise(round(mean(retweet_count)),\n            round(mean(favorite_count)),\n            round(mean(display_text_range))) %>% \n  kable(col.names = c(\"Hora\",\"Retweet\",\"Favorito\",\"Tamanho do Texto\"),caption = \"Médias Referentes ao Assunto Seleção\")o\")\n\n\nMédias Referentes ao Assunto Seleção\n\nHora\nRetweet\nFavorito\nTamanho do Texto\n\n\n\n0\n417\n0\n119\n\n\n1\n173\n2\n133\n\n\n2\n91\n1\n126\n\n\n3\n169\n0\n131\n\n\n4\n241\n1\n133\n\n\n5\n123\n1\n124\n\n\n6\n148\n1\n134\n\n\n7\n124\n14\n138\n\n\n8\n223\n3\n134\n\n\n9\n87\n14\n139\n\n\n10\n81\n6\n131\n\n\n11\n91\n34\n129\n\n\n12\n195\n44\n126\n\n\n15\n176\n4846\n151\n\n\n\n\n\nEscolhendo um perfil dessa vez. Aproveitando que é semana de champions escolhi o Vinícius Junior do Real Madrid.\n\nvinijr <- search_tweets(\"@vinijr\", n = 3000)\n\nQuais idiomas presentes nos tweets?\n\nunique(vinijr$lang)\n\n [1] \"und\" \"es\"  \"en\"  \"it\"  \"ht\"  \"fr\"  \"pt\"  \"in\"  \"cy\"  \"ar\"  \"ca\"  \"eu\" \n[13] \"fi\"  \"nl\"  \"tl\"  \"et\"  \"lv\"  \"no\"  \"tr\" \n\n\nDesconsiderando o português qual a porcetagem de presença dos tweets?\n\nvinijr %>% filter(lang != \"pt\") %>% \n  group_by(lang) %>% \n  summarise(contagem=n()) %>%\n  arrange(desc(contagem)) %>% \n  slice(1:5) %>%\n  mutate(\n    langEx = case_when(lang ==\"ar\"~\"Árabe\"\",\n                     lang ==\"es\"~\"Espanhol\",\n                     lang ==\"fr\"~\"Francês\"\",\n                     lang ==\"en\"~\"Inglês\"\", \n                     lang ==\"und\"~\"Não Detectado\"\",\n                     )) %>% \n   \n  mutate(Perc = round(contagem /sum(contagem)*100 ,2 )) %>% \n  ggplot(aes(x= langEx,y =Perc,label = Perc)) +\n  geom_col(fill =\"gray\") +\n    \n  geom_text(position = position_stack(vjust =1.05),\n           color=\"#030202\") +\n  labs(\n    title= \"Os 5 Idiomas mais Presentes nos Tweets do @vinijr\",\n       subtitle = \"Desconsiderando o Português\"\", x=\"\"\", \n       y ='Porcentagem (%)') +\n   theme(axis.ticks.x=element_blank(),\n          axis.text.y =element_blank())"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#conclusão",
    "href": "posts/Twitter/API_Twitter.html#conclusão",
    "title": "Como usar API do Twitter",
    "section": "Conclusão",
    "text": "Conclusão\nEmbora eu tenha descartado a maioria das colunas, estou impressionado pelo volume de informação que a API disponibiliza para o usuário (43 colunas) um leque absurdo de análises que podem ser feitas. A parte mais complexa é estabelecer a conexão com a API mas uma vez feita basta se atentar no tempo de validade das chaves."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#autenticando",
    "href": "posts/Twitter/API_Twitter.html#autenticando",
    "title": "Como usar API do Twitter",
    "section": "Autenticando",
    "text": "Autenticando\n\ntwitter_token = create_token()\nauth_as(twitter_token)"
  }
]