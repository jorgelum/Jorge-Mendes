[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jorge L. Mendes",
    "section": "",
    "text": "Me chamo Jorge. Sou graduando em Engenharia Química pela Universidade Federal de São Paulo.\nComecei a ter afinidade pela linguagem R no final de 2020 e me apaixonei pelo RMarkdown/Quarto."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jorge Mendes",
    "section": "",
    "text": "Otimização\n\n\n\n\n\n\n\nlpsolve\n\n\n\n\nOtimização utilizando a linguagem R\n\n\n\n\n\n\nMar 2, 2023\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nPoder de Compra e Big Mac\n\n\n\n\n\n\n\nEconomics\n\n\nggplot\n\n\ndplyr\n\n\n\n\nO big mac é um dos pratos mais famosos do mcdonalds e virou uma ferramenta de estudos econômicos\n\n\n\n\n\n\nFeb 27, 2023\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nMapa Eleitoral\n\n\n\n\n\ndasd dsa\n\n\n\n\n\n\nNov 11, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nUsando R para acessar google sheet\n\n\n\n\n\nIsso é um pequeno tutorial para acessar o google sheets com a biblioteca googlesheets4 e base de dados utilizada vai ser da copa do mundo.\n\n\n\n\n\n\nNov 5, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nExtraindo dados da wikipedia\n\n\n\n\n\n\n\nweb scraping\n\n\nparlamento\n\n\ngoverno\n\n\nReino Unido\n\n\n\n\nWeb Scraping da página da Wikipédia\n\n\n\n\n\n\nNov 3, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nComo usar API do Twitter\n\n\n\n\n\n\n\napi\n\n\nseleção\n\n\ntwitter\n\n\n\n\nUm tutorial básico de como acessar a API do Twitter para obter dados\n\n\n\n\n\n\nOct 10, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nSaneamento no Estado de São Paulo\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nsaneamento\n\n\ncsv\n\n\ngeobr\n\n\nggplot\n\n\n\n\nAtlas do Esgoto\n\n\n\n\n\n\nSep 10, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nCampeonato Brasileiro\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nfutebol\n\n\n\n\nAnalisando os resultados do campeonato brasileiro\n\n\n\n\n\n\nJul 14, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\n  \n\n\n\n\nPetróleo\n\n\n\n\n\n\n\nanalysis\n\n\nnew\n\n\ncode\n\n\nANP\n\n\n\n\nPanorama a respeito do petróleo e biblioteca ggplot\n\n\n\n\n\n\nJul 4, 2022\n\n\nJorge Luiz Mendes\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html",
    "href": "posts/Petroleum/Petroleum.html",
    "title": "Petróleo",
    "section": "",
    "text": "Atualizado1 : 23/03/2023"
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html#bibliotecas",
    "href": "posts/Petroleum/Petroleum.html#bibliotecas",
    "title": "Petróleo",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(tidyverse)\nlibrary(gghighlight)\nlibrary(magrittr)\nlibrary(plyr)\nlibrary(knitr)\nlibrary(geobr)\nlibrary(glue)\n\n\n\n\n\n\n\nE para que servem essas bibliotecas?\n\n\n\nO Tidyverse é um conjunto de bibliotecas muito útil que pode ser carregada rapidamente.\n\n\n\n\n\nreadr: Importar/Carregar dados;\ndplyr(tidyr, tibble, plyr): Manipulação e transformação de dados;\nggplot: Visualização de dados;\nmagrittr: Operador Pipe(“O velho %>%”) facilita a escrita do código. Também existe o novo pipe (“|>”) nativo nas versões atuais do RStudio;\nknitr: Ajuda a formatar tabelas."
  },
  {
    "objectID": "posts/Petroleum/Petroleum.html#visão-geral",
    "href": "posts/Petroleum/Petroleum.html#visão-geral",
    "title": "Petróleo",
    "section": "Visão Geral",
    "text": "Visão Geral\nQuais países possuem as maiores reservas de petróleo?\nCarregando os dados.\n\nReserva_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-1.csv\")\n\nPlotando o Gráfico.\n\nReserva_internacional %>% filter(ANO ==2020) %>% \n  arrange(desc(`VALOR DA RESERVA`)) %>% slice(1:10) %>% \n    ggplot() +\n    geom_col(aes(x =`VALOR DA RESERVA`,y =reorder(PAÍS,`VALOR DA RESERVA`),\n            fill = BLOCO) ) +\n          scale_fill_manual(values = c(\"#de6d04\",\"#0f7a38\")) +\n          labs(x =\"Bilhões de Barris\", y = \"\",\n               title =\"As 10 Maiores Reservas de Petróleo\",\n               subtitle =\"em 2020\" ,\n               caption = \"Mendes,Jorge L.\") +\n  \n         \n    theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\nA OPEP (Organização dos Países Exportadores de Petróleo) é uma organização que tem por objetivo regular a produção do petróleo para dar estabilidade no mercado internacionall.\nQuem são maiores produtores?\nCarregando os dados.\n\nProducao_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-2.csv\")\n\nProducao_internacional$PRODUÇÃO <- round(Producao_internacional$PRODUÇÃO,2)\n\nPlotando o Gráfico adicionando labels.\n\n Producao_internacional %>% filter(ANO == 2020) %>% \n  arrange(desc(PRODUÇÃO)) %>% \n   slice(1:10) %>% \n   mutate(label = glue::glue(\"{round(PRODUÇÃO/1000,2)}k\")) %>%  \n  ggplot() +\n   aes(x =PRODUÇÃO ,y =reorder(PAÍS,PRODUÇÃO),\n                fill=BLOCO, label =label) +\n   geom_col() +\n        scale_fill_manual(values = c(\"#de6d04\",\"#0f7a38\")) +\n         labs(x =\"Milhares de Barris por Dia\", y = \"\",\n              title = \"Os 10 Maiores Produtores de Petróleo\",\n              subtitle =\"em 2020\",\n              caption = \"Mendes,Jorge L.\") +\n        geom_label(size = 3) +\n    scale_x_continuous(limits = c(0,17000),\n                       labels = function(x){\n                       glue::glue(\"{x/1000}k\")}) +\n   \n    theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\nEmbora o Brasil não tenha as maiores reservas de petróleo, ele pertence ao grupo dos maiores produtores.\nAgora podemos analizar a produção anual de petróleo do Brasil.\n\n#Texto com quebra de linha\nTexto <- paste(\n  strwrap(\"Aumento da extração de petróleo do Pré-Sal no ano de 2015\",\n          20),\n  collapse = \"\\n\")\n\nano_destacado <- Producao_internacional %>% \n  filter(ANO == 2015,PAÍS == \"Brasil\") %>%\n  mutate(label = glue::glue(\"{PRODUÇÃO}\"))\n\n\nProducao_internacional %>% filter(PAÍS ==\"Brasil\") %>% \n  ggplot() +\n   aes(x = ANO,y=round(PRODUÇÃO,2)) +\n \n  geom_line(size =1.2,colour = \"grey\" ) +\n    scale_x_continuous(\n      breaks =c(2011:2020)) +\n  labs(y = \"Milhares de Barris por dia\",x =\"Ano\",\n       title = \"\",\n       subtitle = \"\",\n       caption = \"Mendes, Jorge L.\") +\n  \n  geom_point(size = 3, \n             colour = \"grey\") +\n  \n  \n  \n  #Textos\n  annotate(\"text\",x = 2012 ,y =3000,size = 6,\n           label = \"BRASIL\", fontface = \"bold\",colour = \"#36674e\") +\n  annotate(\"text\",x = 2016 ,y =2300,size= 4,\n           label = Texto, fontface = \"bold\",colour = \"#243bd4\") +\n   \n  #destacar um ponto\n  ggrepel::geom_text_repel(\n    data = ano_destacado,\n    aes(x =ANO,y = PRODUÇÃO,label =label),\n    nudge_x = -0.5,\n    nudge_y = 50,\n    color = \"#243bd4\",\n    size = 5,\n    arrow = NULL\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nQuem foram os maiores consumidores em 2020?\nCarregando os dados.\n\nconsumo_internacional <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-1-panorama-internacional/dados-abertos-csv/anuario-2021-dados_abertos-tabela1-3.csv\")\n\nUsando o pacote knitr para formatar tabelas.\n\nconsumo_internacional %>% \n  filter(ANO ==2020) %>% select(2:3) %>%  \n  arrange(desc(`CONSUMO DE PETRÓLEO`)) %>% slice(1:10) %>% \n  head(10) %>% \n  knitr::kable(col.names = c(\"País\",\"Consumo de Petróleo (mil barris por dia)\"))\n\n\n\nPaís\nConsumo de Petróleo (mil barris por dia)\n\n\n\nEstados Unidos\n17178\n\n\nChina\n14225\n\n\nÍndia\n4669\n\n\nArábia Saudita\n3544\n\n\nJapão\n3268\n\n\nRússia\n3238\n\n\nCoreia do Sul\n2560\n\n\nBrasil\n2323\n\n\nCanadá\n2282\n\n\nAlemanha\n2045\n\n\n\n\n\nE no Brasil? Quais estados tem reserva de petróleo?\nCarregando dados\n\nBr_Reservas <- readr::read_csv2(\"https://www.gov.br/anp/pt-br/centrais-de-conteudo/publicacoes/anuario-estatistico/arquivos-anuario-estatistico-2021-metadados-pdf-e-dados-abertos-csv/secao-2-industria-nacional-do-petroleo-e-do-gas-natural/dados-abertos-csv/anuario-2021-dados_abertos-tabela2-3.csv\")\n\nAqui iremos somar as reservas marítimas e terrestres.\n\n#Vamos agrupar total das reservas(terra e mar)\nTotal_estados <- Br_Reservas %>% filter(ANO == 2020) %>% \n  group_by(`UNIDADES DA FEDERAÇÃO`) %>% \n  dplyr::summarise(\n    sum(\n      Total =`RESERVAS TOTAIS DE PETRÓLEO (EM MILHÕES DE BARRIS)`),\n      Count= n()\n    ) %>% \n  #renomeando as colunas\n  plyr::rename(replace =c(\"sum(Total = `RESERVAS TOTAIS DE PETRÓLEO (EM MILHÕES DE BARRIS)`)\"=\"Total\",\"UNIDADES DA FEDERAÇÃO\" = \"name_state\"))\n #Renomeando alguns itens\nTotal_estados$name_state[Total_estados$name_state ==\"Paraná5\"] <- \"Paraná\"\nTotal_estados$name_state[Total_estados$name_state ==\"Rio de Janeiro3\"] <- \"Rio De Janeiro\"\nTotal_estados$name_state[Total_estados$name_state ==\"Santa Catarina6\"] <- \"Santa Catarina\"\nTotal_estados$name_state[Total_estados$name_state ==\"São Paulo4\"] <- \"São Paulo\"\nTotal_estados$name_state[Total_estados$name_state ==\"Rio Grande do Norte\"] <- \"Rio Grande Do Norte\"\n#Formatando a tabela\nTotal <-Total_estados %>% \n  select(1:2) %>% kable(col.names = c(\"UF\",\"Total\"))\n\nTotal\n\n\n\nUF\nTotal\n\n\n\nAlagoas\n4.040435e+00\n\n\nAmazonas\n5.153600e+01\n\n\nBahia\n2.938644e+02\n\n\nCeará\n2.428873e-01\n\n\nEspírito Santo\n1.314880e+03\n\n\nMaranhão\n2.139806e-01\n\n\nParaná\n0.000000e+00\n\n\nRio Grande Do Norte\n2.662763e+02\n\n\nRio De Janeiro\n1.603287e+04\n\n\nSanta Catarina\n0.000000e+00\n\n\nSergipe\n1.947730e+02\n\n\nSão Paulo\n2.079593e+03\n\n\n\n\n\nPodemos apresentar os resultado na forma de mapa\nA biblioteca geobr nos force uma malha de pontos que podemos usar para construir mapas.\nCarregando os dados de 2017.\n\nMapa <-geobr::read_state(year = 2017)\n\nAgora podemos unir as tabelas\n\n# um pequeno malabarismo para plotar o mapa completo\nv1 <-c(\"Rio Grande Do Sul\",\"Minas Gerais\",\"Mato Grosso Do Sul\",\n       \"Mato Grosso\",\"Goiás\",\"Distrito Federal\",\"Piauí\",\"Paraíba\",\n       \"Pernambuco\",\"Rondônia\",\"Acre\",\"Roraima\",\"Pará\",\"Amapá\",\n       \"Tocantins\")\nv2 <-rep(0,15)\n# selecionar as colunas de interesse\nTotal_estados <- Total_estados %>% select(1:2)\n\n#adicionando linhas ao dataframe\nlinhas <-data.frame(name_state =v1,Total = v2)\n\nTotal_estados <- rbind(Total_estados,linhas)\n\n#Finalmente unindo as tabelas \nEstados <- merge(Mapa, Total_estados, by = c(\"name_state\"))\n\nPlotando o Gráfico.\n\n  Estados %>% ggplot() +\n    geom_sf(aes(fill=Total), color= \"black\", size=.15) +\n      labs(subtitle=\"Reservas Totais Estimadas em 2020\", size=8) +\n      scale_fill_distiller(palette = \"Oranges\",direction=1, \n                           name=\"Milhões de Barris\")"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html",
    "href": "posts/Campeonato Brasileiro/Br.html",
    "title": "Campeonato Brasileiro",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nsummary(cars)\n\n     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html#pay-attention",
    "href": "posts/Campeonato Brasileiro/Br.html#pay-attention",
    "title": "Campeonato Brasileiro",
    "section": "Pay Attention",
    "text": "Pay Attention\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n:::\n```"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Br.html#including-plots",
    "href": "posts/Campeonato Brasileiro/Br.html#including-plots",
    "title": "Campeonato Brasileiro",
    "section": "Including Plots",
    "text": "Including Plots\nYou can also embed plots, for example:\n\n\n\n\n\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html",
    "title": "Campeonato Brasileiro",
    "section": "",
    "text": "Atualizado em 11/09/2022"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html",
    "href": "posts/Saneamento/Saneamento.html",
    "title": "Saneamento no Estado de São Paulo",
    "section": "",
    "text": "Saneamento é um tema de extrema importâcia. Aqui o foco principal é fazer uma análise exploratória simples com dados públicos."
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#bibliotecas",
    "href": "posts/Saneamento/Saneamento.html#bibliotecas",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(magrittr)\nlibrary(knitr)\nlibrary(geobr)\nlibrary(ggspatial)\nlibrary(sf)"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#os-dados",
    "href": "posts/Saneamento/Saneamento.html#os-dados",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Os dados",
    "text": "Os dados\n\nOs dados foram obtidos da agência nacional de águas e saneamento básico ANA.\nFoi utilizado o Atlas Esgotos Situação 2013 - Remoção da Carga de Esgotos Gerada na Sede Municipal e o pacote geobr (Pereira and Goncalves 2021) para acessar informações sobre os dados espaciais do Brasil.\n\ndados <- readr::read_delim(\"Atlas_Esgoto2013.csv\",delim = ',')\n\n\nglimpse(dados)\n\nRows: 5,570\nColumns: 14\n$ FID        <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1~\n$ MUN_CD_MUN <dbl> 1100015, 1100023, 1100031, 1100049, 1100056, 1100064, 11000~\n$ MUN_NM_MUN <chr> \"Alta Floresta D Oeste\", \"Ariquemes\", \"Cabixi\", \"Cacoal\", \"~\n$ MUN_UF     <chr> \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\", \"RO\",~\n$ MUN_NM_PRE <chr> \"Serviço Autônomo de Água e Esgoto\", \"Companhia de Águas e ~\n$ MUN_SIGLA_ <chr> \"SAAE\", \"CAERD\", \"PM\", \"SAAE\", \"PM\", \"PM\", \"PM\", \"PM\", \"PM\"~\n$ MUN_POPU_2 <dbl> 14735, 85770, 2771, 67665, 15276, 14097, 2665, 8689, 22741,~\n$ MUN_ICS    <dbl> 1.4244810, 2.0176413, 0.3713331, 0.0000000, 0.6727235, 1.02~\n$ MUN_IFSUTI <dbl> 1.8468146, 8.5762823, 0.6312662, 16.1786793, 19.6892988, 4.~\n$ MUN_ISCST  <dbl> 96.728704, 89.406076, 98.997401, 28.821321, 79.637978, 94.9~\n$ MUN_C_GERA <dbl> 795, 4631, 149, 3653, 824, 761, 143, 469, 1228, 2088, 2027,~\n$ MUN_C_REMA <dbl> 786, 4393, 149, 1791, 727, 742, 138, 445, 1126, 1907, 1986,~\n$ MUN_EFIC_1 <dbl> 1.1080888, 5.1457694, 0.3787597, 50.9572076, 11.8135793, 2.~\n$ MUN_ICT_FI <dbl> 0.000000, 0.000000, 0.000000, 55.000000, 0.000000, 0.000000~"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#manipulando-as-bases",
    "href": "posts/Saneamento/Saneamento.html#manipulando-as-bases",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Manipulando as Bases",
    "text": "Manipulando as Bases\nRenomeando as colunas (consultei o aplicativo do ANA).\n\ndados <- dados %>% \n    dplyr::rename( \n        c(\"code_muni\" = \"MUN_CD_MUN\",\"municipio\"=\"MUN_NM_MUN\" ,\n          \"uf\"=\"MUN_UF\", \"prestador_servico\"= \"MUN_NM_PRE\" ,\n          \"sigla_prestador\"=\"MUN_SIGLA_\"  ,\n          \"populacao2013\" =\"MUN_POPU_2\" , \n                \n          \"Parcela_População_Com_Coleta_Sem_Tratamento(%)\")= =\n            \"MUN_ICS\",\n                \n          \"Parcela_População_Com_Solução_Individual(%)\"(=)\" =\n            \"MUN_IFSUTI\" ,\n                \n          \"Parcela_População_Sem_Coleta_Sem_Tratamento(%)\")= =\n            \"MUN_ISCST\",\n                \n          \"Parcela_População_Com_Coleta_Com_Tratamento(%)\")= =\n            \"MUN_ICT_FI\",\n                \n          \"Carga_Gerada\"= \"MUN_C_GERA\",\n          \"Carga_Remanescente\" =\"MUN_C_REMA\"  ,\n          \"Remoção_Carga_Orgânica(DBO)(%)\"=\"MUN_EFIC_1\"))\"))\n\nPodemos gerar tabelas com o pacote knitr para gerar tabelas.\nQuais cidades geram maior carga de esgoto no estado de são paulo?\n\ndados %>% filter(uf == \"SP\") %>% \n  select(c(\"municipio\",\"Carga_Gerada\")) %>% \n  arrange(desc(Carga_Gerada)) %>% \n  slice(1:10) %>% \n  knitr::kable(col.names = \n                 c(\"Municípios\"\"\"Carga Gerada Total (kgDBO/dia)\")),\n               \"simple\",caption = \"Estado de São Paulo\"))\n\n\nEstado de São Paulo\n\nMunicípios\nCarga Gerada Total (kgDBO/dia)\n\n\n\nSão Paulo\n604822\n\n\nGuarulhos\n65986\n\n\nCampinas\n57323\n\n\nSão Bernardo do Campo\n43263\n\n\nOsasco\n40435\n\n\nSanto André\n38211\n\n\nSão José dos Campos\n35351\n\n\nRibeirão Preto\n32560\n\n\nSorocaba\n31355\n\n\nSantos\n22833\n\n\n\n\n\nCarregando os dados do geobr para o estado de São Paulo.\n\nmapa <- geobr::read_municipality(code_muni = 35,year = 2018)\n\nUsing year 2018\n\n\nUnindo as tabelas\n\nsp <- dados %>% filter(uf ==\"SP\") %>% merge(mapa)\nnrow(sp) # verificando se possui as 645 cidades do estado de sp\n\n[1] 645\n\n\nAgora podemos gerar mapas com os pontos geom.\nQuais cidades geram mais carga de esgoto no estado de São Paulo?\n\nsp  %>% ggplot() +\n  geom_sf(aes(fill = Carga_Gerada, geometry = geom)) + \n  labs(title = \"Situação do Estado de São Paulo\"lo\",\n       subtitle = \"Carga Total Gerada 2013\") +\n  scale_fill_distiller(palette = \"Reds\",direction = 1,\n                       name= \"KgDBO/dia\") +\n  theme(axis.title=element_blank(),\n                   axis.text=element_blank(),\n                   axis.ticks=element_blank())\n\n\n\n\nPodemos verificar uma região específica ( como um conjunto de cidades). A forma mais segura é utilizar os códigos dos municípios, algumas cidades compartilham o mesmo nome.\nQual a porcentagem da população com coleta e tratamento de esgoto na região do grande ABC?\nAproveitei e adicionei o nome dos municípios, eixos das coordenadas, escala e a indicação do norte.\n\nlistaABC = list(3548708, 3547809, 3529401, 3513801, 3548807, 3543303, 3544103)\n\nsp %>%  filter(code_muni %in% listaABC) %>%\n  ggplot() + \n  geom_sf(aes(fill = `Parcela_População_Com_Coleta_Com_Tratamento(%)`)`,\n              geometry = geom)) +\n  \n  geom_sf_label(aes(label = municipio,geometry =geom),\n                label.padding = unit(0.5,\"mm\"),\n                size = 2) +\n  \n  \n  labs(title = \"Parcela da População Com Coleta e Com Tratamento\"o\",\n       subtitle = \"Região do Grande ABC, 2013 \"\",\n       x = \"Longitude\",y =\"Latitude\") +\n  \n  scale_fill_distiller(palette = \"Greens\",direction = 1,\n                       name= \"(%)\") +\n  annotation_north_arrow(location = \"br\") +\n  annotation_scale(location =\"bl\"\n                   )\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#referências",
    "href": "posts/Saneamento/Saneamento.html#referências",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Referências",
    "text": "Referências\n\nBea Milz"
  },
  {
    "objectID": "posts/Saneamento/Saneamento.html#ver-também",
    "href": "posts/Saneamento/Saneamento.html#ver-também",
    "title": "Saneamento no Estado de São Paulo",
    "section": "Ver também",
    "text": "Ver também\n\nBea Milz"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#objetivo",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#objetivo",
    "title": "Campeonato Brasileiro",
    "section": "Objetivo",
    "text": "Objetivo\nExplorar a biblioteca brasileirão (Amorim 2022) . É uma boa base para praticar, principalmente, manipulações de dataframe.\nEla consegue, além de outras coisas, retornar jogos, a data, o placar e os clubes envolvidos desde 2003 no campeonato brasileiro de futebol."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#bibliotecas",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#bibliotecas",
    "title": "Campeonato Brasileiro",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(dplyr) #tratamento de dados\nlibrary(tidyr) #tratamento de dados\n\nlibrary(magrittr) #o pipe antigo\nlibrary(purrr) #programação funcionalal\nlibrary(lubridate) #tratar datas\nlibrary(knitr) #formatação de tabelasas\n\nlibrary(brasileirao) #base de dados utilizados\n\nlibrary(ggplot2) #gráficoss\nlibrary(treemap) #gráficoss\n\nlibrary(jpeg) #adicionar imagens\nlibrary(patchwork)  #adicionar imagens"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#mão-na-massa",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#mão-na-massa",
    "title": "Campeonato Brasileiro",
    "section": "Mão na Massa",
    "text": "Mão na Massa\nCarregando dados.\n\nBr <- brasileirao::matches\n\nPodemos expor os resultados na forma de tabela.\n\nknitr::kable(head(Br),align = \"lccrr\")\n\n\n\nseason\ndate\nhome\nscore\naway\n\n\n\n2003\n2003-03-29\nAthletico PR\n2x0\nGrêmio\n\n\n2003\n2003-03-29\nGuarani\n4x2\nVasco\n\n\n2003\n2003-03-30\nCorinthians\n0x3\nAtlético MG\n\n\n2003\n2003-03-30\nGoiás\n2x2\nPaysandu\n\n\n2003\n2003-03-30\nCriciúma\n2x0\nFluminense\n\n\n2003\n2003-03-30\nCruzeiro\n2x2\nSão Caetano\n\n\n\n\n\nVerificando os tipos de variáveis das colunas.\n\nglimpse(Br)\n\nRows: 8,026\nColumns: 5\n$ season <dbl> 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 2003, 200~\n$ date   <date> 2003-03-29, 2003-03-29, 2003-03-30, 2003-03-30, 2003-03-30, 20~\n$ home   <chr> \"Athletico PR\", \"Guarani\", \"Corinthians\", \"Goiás\", \"Criciúma\", ~\n$ score  <chr> \"2x0\", \"4x2\", \"0x3\", \"2x2\", \"2x0\", \"2x2\", \"1x1\", \"0x0\", \"1x1\", ~\n$ away   <chr> \"Grêmio\", \"Vasco\", \"Atlético MG\", \"Paysandu\", \"Fluminense\", \"Sã~\n\n\nRealizando algumas manipulações para obter resultados dos jogos a partir de 2010.\n\nTabela_extendida <- Br  %>% filter(season >=2010)  %>% \n  separate(score,\n           c(\"Placar_Mandante\",\"Placar_Visitante\"),\n           sep = \"x\",\n           convert = TRUE,\n           remove = FALSE\n    \n  ) %>% \n  mutate(\n    Mandante = case_when(\n      Placar_Mandante > Placar_Visitante~\"Venceu\",\n      Placar_Mandante < Placar_Visitante~\"Perdeu\",\n      Placar_Mandante == Placar_Visitante~\"Empate\"\n    ),\n     Visitante = case_when(\n      Placar_Mandante < Placar_Visitante~\"Venceu\",\n      Placar_Mandante > Placar_Visitante~\"Perdeu\",\n      Placar_Mandante == Placar_Visitante~\"Empate\"\n    )\n  )\n\nA ideia aqui é selecionar um clube e fazer as análises a partir dessa escolha. Vamos criar uma função para selecionar um time.\n\nClube<-function(dataframe,Time){\n  #selecionar o clube quando ele é mandantee\n        TimeMandante <-dataframe %>% filter(home==Time) %>% \n            select(season,date,home,Placar_Mandante,\n            Placar_Visitante,Mandante,away) %>% \n            rename(\n                    \"clube\"=\"home\",\n                    \"Gols_Pro\"=\"Placar_Mandante\",\n                    \"Gols_Contra\"=\"Placar_Visitante\",\n                    \"Resultado\"=\"Mandante\",\n                    \"adversario\" =\"away\") %>% \n            mutate(mando = \"Mandante\")\n  \n  #selecionar o clube quando ele é visitantee\n        TimeVisitante <- dataframe %>% \n            filter(away==Time) %>% \n            select(season,date,away,Placar_Visitante,\n            Placar_Mandante,Visitante,home) %>% \n            rename(\n                    \"clube\"=\"away\",\n                    \"Gols_Pro\"=\"Placar_Visitante\",\n                    \"Gols_Contra\"=\"Placar_Mandante\",\n                    \"Resultado\"=\"Visitante\",\n                     \"adversario\"=\"home\") %>% \n            mutate(mando = \"Visitante\")\n  \n  #Unindo as tabelas\n        Resultados <-rbind(TimeMandante,TimeVisitante)\n  \n  return(Resultados)\n  \n}\n\nSelecionando um time.\nO interessante é selecionar um clube que jogou muitas edições para ter uma boa quantidade de dados. Convenientemente foi selecionado o Corinthians.\n\n\n\n\n\nTimao<-Clube(dataframe= Tabela_extendida,Time =\"Corinthians\")\n\nÉ interessante adicionar os pontos obtidos em cada partida.\n\nTimao <- Timao %>% mutate(\n  Pontos = case_when(\n  Resultado ==\"Venceu\"~3,\n  Resultado ==\"Empate\"~1,\n  Resultado ==\"Perdeu\"~0,\n))\n\nUsando o pacote lubridate é possível tratar datas, obtendo informações sobre o dia,dia da semana, mês e ano de forma isolada.\n\n#Timao$dia_Mes <- lubridate::day(Timao$date)\nTimao$Mes <- lubridate::month(Timao$date, label = TRUE)\n#Timao$NdiaSemana <- lubridate::wday(Timao$date)\n\nQual o número de vitórias, empates e derrotas da última década?\n\nTimao %>% filter(!is.na(Pontos)) %>% count(Resultado) %>%  \n  treemap(index = c(\"n\",\"Resultado\"),\n          vSize = \"n\",\n          align.labels=list(c(\"center\", \"center\"),c(\"center\", \"top\")),\n          title = \"Resultados do Corinthians desde 2010\",\n          fontsize.labels=c(15,12),\n          palette = c(\"#cfc6c6\",\"#3d3a3a\",\"#0a0a0a\")\n           \n           )\n\n\n\n\nCom a função group_by e summarise podemos agrupar os dados.\n\nDadosAgg <- Timao %>% \n\n  filter(!is.na(Pontos)) %>% \n\n  group_by(Mes)%>% \n\n  summarise(\n\n    MediaPontos = round(mean(Pontos),2),\n    GolsPro = sum(Gols_Pro),\n    GolsContra =sum(Gols_Contra)) %>%\n\n    arrange(desc(Mes))\n\nDadosAgg %>% knitr::kable(col.names =\n                            c(\"Mês\"\"\"Pontos\"\"\"Gols Pro\"\"\"Gols Contra\")))\n\n\n\nMês\nPontos\nGols Pro\nGols Contra\n\n\n\ndez\n1.11\n16\n19\n\n\nnov\n1.82\n85\n58\n\n\nout\n1.40\n87\n80\n\n\nset\n1.37\n89\n77\n\n\nago\n1.56\n88\n69\n\n\njul\n2.00\n81\n35\n\n\njun\n1.71\n62\n38\n\n\nmai\n1.84\n53\n32\n\n\nabr\n1.78\n16\n9\n\n\nfev\n1.00\n6\n7\n\n\njan\n1.20\n9\n8\n\n\n\n\n\nQual mês, em média, fez mais pontos?\n\n DadosAgg%>% \n    \n    \n    ggplot(aes(x =MediaPontos ,y =Mes, label = MediaPontos)) +\n\n    geom_col(fill = \"gray\")+\n\n     \n    geom_text(\n            position = position_stack(vjust =1.05),\n            color=\"#030202\") +\n    \n    labs(x = \"Pontos\",y = \"Mês\"\", title==\"Média de Pontos em Cada Mês\"ªs\",\n         subtitle = \"valores a partir de 2010\") +\n    theme(axis.text.x = element_blank(),axis.ticks.x=element_blank(),\n          axis.text.y =element_text(face =\"bold\",\n                                    colour = \"#030202\"))\n\n\n\n\nEm quais mêses, fez e tomou ,mais gols?\n\nDadosAgg %>%  ggplot() +\n    \n    geom_col(aes(x = -GolsPro ,y =Mes), fill=\"#424d6b\") +\n\n     \n    geom_text(aes(x = -GolsPro ,y =Mes,label =GolsPro),\n            position = position_stack(vjust =0.5),\n            color =\"#ced2de\") +\n    \n    geom_col(aes(x = GolsContra,y =Mes), \n              fill=\"#806630\") +\n\n     \n    geom_text(aes(x =GolsContra ,y =Mes,label =GolsContra),\n            position = position_stack(vjust =0.5),\n            color=\"#030202\") +\n   annotate(\"text\",x = -50 ,y =2,label =\"Gols Pro\",\n            color =\"#424d6b\") +\n   annotate(\"text\",x = 50 ,y =2,label =\"Gols Contra\",\n            color =\"#806630\") +\n    \n    \n    labs(x = \"Gols\",y = \"Mês\"\", title==\"Total de Gols por Mês\"s\",\n         subtitle = \"valores a partir de 2010\") +\n    theme(axis.text.x = element_blank(),\n          axis.ticks.x=element_blank(),\n          axis.text.y =element_text(face =\"bold\",\n                                    colour = \"#030202\"))\n\n\n\n\nQual o desempenho das últimas temporadas?\n\nano <- c(2011,2015,2017)\npontuacao <-\n  Timao %>% filter(!is.na(Pontos)) %>% \n  group_by(season) %>% \n  summarise(Pontos = sum(Pontos)) %>% \n  mutate(Titulo = ifelse(season %in% ano, \"Campeão\"\",\"Não Ganhou\")))) \n\n\nTexto <- paste(\n  strwrap(\"A temporada de 2022 ainda não foi concluída\"a\",\n          20),\n  collapse = \"\\n\")\n\npath <-\"escudo1.jpg\"\nimg <- readJPEG(path,native = TRUE)\n\n\npontuacao %>% \n  ggplot() +\n    geom_line(aes(x = season, y = Pontos),size =1.4,colour =\"grey\") +\n    scale_x_continuous(breaks = c(2010:2022)) +\n    geom_point(aes(x = season, y = Pontos),size = 2,color=\"grey\") +\n    \n    geom_point(\n      aes(x = season,y=Pontos, color =Titulo, size= Titulo)) +\n    \n    scale_colour_manual(values = c(\"#0a0a0a\",\"#b3a6a6\")) +\n\n    scale_size_manual(values = c(3,2)) +\n    \n    geom_line(aes(x = c(2010:2022),y = mean(`Pontos`)),\n              linetype =2) +  \n  \n    labs(x =\"Temporada\",title = \"Desempenho do Clube\") +\n    \n    theme(axis.text.x = element_text(angle = 90)) +\n    \n    annotate(\"text\",x = 2011 ,y =60,size = 2,\n           label = \"Média\"\", fontface==\"bold\"\",colour==\"black\"))++\n    annotate(\"text\",x = 2018 ,y =35,size = 4,\n           label = Texto, fontface = \"bold\",colour = \"red\") +\n    inset_element(p = img,\n                left = 1.00,\n                bottom = 0.65,\n                right = 1.35,\n                top = 1.15)"
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#conclusão",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#conclusão",
    "title": "Campeonato Brasileiro",
    "section": "Conclusão",
    "text": "Conclusão\nA biblioteca brasileirao é excelente . Foi possível extrair bastante informação. Ela fornece de forma simples os dados gerais sobre as partidas, infelizmente ela não trás informações como número de cartões, tempo de jogo sem interrupções, posse bola, e entre outras. Não é terra arrasada, pois outros dados de fontes distintas podem ser adicionados para complementar as análises."
  },
  {
    "objectID": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#ver-também",
    "href": "posts/Campeonato Brasileiro/Campeonato Brasileiro.html#ver-também",
    "title": "Campeonato Brasileiro",
    "section": "Ver também",
    "text": "Ver também\n\nr - graph - gallery\nBlog Curso -R"
  },
  {
    "objectID": "posts/Premier League/Premier League.html",
    "href": "posts/Premier League/Premier League.html",
    "title": "Premier League",
    "section": "",
    "text": "a <- c(0:40)\n print(a)\n##  [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n## [26] 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html",
    "href": "posts/Twitter/API_Twitter.html",
    "title": "Como usar API do Twitter",
    "section": "",
    "text": "API ou interface de programação de aplicação é basicamente uma ferramenta que estabelece uma comunicação entre sistemas. Nela é possível que realizar troca de informações de forma segura utilizando diferentes linguagens de programação.\nO Twitter fornece API para consumo de dados para algumas lnguagem como python, R, entre outras. O R possui uma biblioteca específica para isso chamada rtweet (Kearney 2019)."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#primeiros-passos",
    "href": "posts/Twitter/API_Twitter.html#primeiros-passos",
    "title": "Como usar API do Twitter",
    "section": "Primeiros passos…",
    "text": "Primeiros passos…\nInicialmente devesse criar uma conta no Twitter e em seguida criar uma conta de desenvolvedor na própria plataforma. Ao criar um projeto e um aplicativo serão geradas chaves de acesso para a requisição de dados via API.\n\n\nPortal do Desenvolvedor\n\n\n\n\n\n\n\n\nAo criar a conta lembre-se de ativar a autenticação em dois fatores."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#bibliotecas",
    "href": "posts/Twitter/API_Twitter.html#bibliotecas",
    "title": "Como usar API do Twitter",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\n#install.packages(\"rtweet\")\n#install.packages(\"wordcloud\")\n#install.packages(\"tm\")\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(magrittr)\nlibrary(lubridate)\nlibrary(knitr)\nlibrary(rtweet)\nlibrary(wordcloud)\nlibrary(tm)\n\nExistem 3 formas simples de se fazer a autenticação:\n\n\nUsando as chaves\nLogin\nUsando rtweet app\n\n\n\n\nNa função mencionada create_token basta inserir os argumentos fornecidos na hora de criar o app.\n\napp\nconsumer key\nconsumer secret\naccess token\naccess secret\n\n\n\n\n\nCaso tenha algum tipo de problema com o primeiro método, é possível utilizar a mesma função create_token sem argumentos. Neste caso você será levado a uma página de login do Twitter e um código de autenticação será enviado um código para o seu celular.\n\n\n\n\n\nOutra opção é usar a função rtweet_app, nesse caso uma tela e será necessário fornecer a Bearer token.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscolha\n\n\n\n\n\nEu tive problemas com a primeiro e terceiro método de autenticação. Uma análise mais profunda da documentação do pacote possa revelar a solução mas na ausência de tempo escolhi o que funcionou sem ter nenhum erro.\nA função create_token foi descontinuada a partir da versão 1.0.0 do pacote rtweet e a função rtweet_app é mais indicada para versão 1.0.2 .\n\n\n\n\n\n\n\n\n\nCuidado!!! Sempre proteja suas chaves.\n\n\n\n\n\nEsse não é o caso mas existem API’s que são pagas, além do prejuízo financeiro, a ideia de terceiros utilizarem para fins duvidosos já causa preocupação. Caso interesse em disponizibilizar seus scripts existem métodos seguros para proteger senhas e chaves, mas como não é o foco dessa postagem tem esse blog."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#ver-também",
    "href": "posts/Twitter/API_Twitter.html#ver-também",
    "title": "Como usar API do Twitter",
    "section": "Ver Também",
    "text": "Ver Também\n\nCéline Van den Rul"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#manipulações",
    "href": "posts/Twitter/API_Twitter.html#manipulações",
    "title": "Como usar API do Twitter",
    "section": "Manipulações",
    "text": "Manipulações\nApós a autenticação podemos iniciar nossas análises .\nCom a função search_tweets ajuda a fazer busca por assuntos ou perfis. Podemos escolher o número de tweets, o idioma, entre outras opções.\nNesse caso trouxemos 3000 tweets com o assunto seleção.\n\nselecao <- search_tweets(\"seleção\", n=3000)\n\nAntes de fazer visualizações devemos fazer uma limpeza nos dados.\n\n# Remove retweets e replies\nselecao_tweets_organic <- selecao %>% filter(\n  retweeted == FALSE, is.na(in_reply_to_status_id)\n                                             ) \n# converte o tipo \nselecao_tweets_organic$full_text <- as.character(\n selecao_tweets_organic$full_text)\n\n#selecionar só as colunas que serão utilizadasas\nselecao_tweets_organic <-selecao_tweets_organic %>% select(created_at,full_text,retweet_count,favorite_count,display_text_range,lang)\n\n# removendo palavras que não fazem sentido para análisese\nselecao_tweets_organic$full_text <- gsub(\"com\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"que\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"pra\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"blimag\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"tô\"\"\"\"\"selecao_tweets_organic$full_text))\nselecao_tweets_organic$full_text <- gsub(\"por\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"bolsonaro\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"uma\",\"\",selecao_tweets_organic$full_text)\nselecao_tweets_organic$full_text <- gsub(\"Bolsonaro\",\"\",selecao_tweets_organic$full_text)\n\nUma nuvem de palavras é um tipo de visualização muito boa para dados textuais e para executar essa tarefa temos a biblioteca wordcloud nela podemos passar uma coluna de dataframe como dado de entrada.\n\nset.seed(1234) # reprodutibilidade\n\n\nwordcloud(selecao_tweets_organic$full_text, \n          min.freq=5, scale=c(3.5, .5), \n          random.order=FALSE, rot.per=0.45, \n          colors=brewer.pal(8, \"Dark2\"))\n\n\n\n\nPodemos fazer análises com base no horário em que o tweet foi criado.\n\nselecao_tweets_organic$hora_criada <-lubridate::hour(selecao_tweets_organic$created_at)\n\nEm média qual horário teve mais Retweet, Favoritoe e Tamanho de Texto?\n\nselecao_tweets_organic %>% group_by(hora_criada) %>%\n  summarise(round(mean(retweet_count)),\n            round(mean(favorite_count)),\n            round(mean(display_text_range))) %>% \n  kable(col.names = c(\"Hora\",\"Retweet\",\"Favorito\",\"Tamanho do Texto\"),caption = \"Médias Referentes ao Assunto Seleção\")o\")\n\n\nMédias Referentes ao Assunto Seleção\n\nHora\nRetweet\nFavorito\nTamanho do Texto\n\n\n\n0\n417\n0\n119\n\n\n1\n173\n2\n133\n\n\n2\n91\n1\n126\n\n\n3\n169\n0\n131\n\n\n4\n241\n1\n133\n\n\n5\n123\n1\n124\n\n\n6\n148\n1\n134\n\n\n7\n124\n14\n138\n\n\n8\n223\n3\n134\n\n\n9\n87\n14\n139\n\n\n10\n81\n6\n131\n\n\n11\n91\n34\n129\n\n\n12\n195\n44\n126\n\n\n15\n176\n4846\n151\n\n\n\n\n\nEscolhendo um perfil dessa vez. Aproveitando que é semana de champions escolhi o Vinícius Junior do Real Madrid.\n\nvinijr <- search_tweets(\"@vinijr\", n = 3000)\n\nQuais idiomas presentes nos tweets?\n\nunique(vinijr$lang)\n\n [1] \"und\" \"es\"  \"en\"  \"it\"  \"ht\"  \"fr\"  \"pt\"  \"in\"  \"cy\"  \"ar\"  \"ca\"  \"eu\" \n[13] \"fi\"  \"nl\"  \"tl\"  \"et\"  \"lv\"  \"no\"  \"tr\" \n\n\nDesconsiderando o português qual a porcetagem de presença dos tweets?\n\nvinijr %>% filter(lang != \"pt\") %>% \n  group_by(lang) %>% \n  summarise(contagem=n()) %>%\n  arrange(desc(contagem)) %>% \n  slice(1:5) %>%\n  mutate(\n    langEx = case_when(lang ==\"ar\"~\"Árabe\"\",\n                     lang ==\"es\"~\"Espanhol\",\n                     lang ==\"fr\"~\"Francês\"\",\n                     lang ==\"en\"~\"Inglês\"\", \n                     lang ==\"und\"~\"Não Detectado\"\",\n                     )) %>% \n   \n  mutate(Perc = round(contagem /sum(contagem)*100 ,2 )) %>% \n  ggplot(aes(x= langEx,y =Perc,label = Perc)) +\n  geom_col(fill =\"gray\") +\n    \n  geom_text(position = position_stack(vjust =1.05),\n           color=\"#030202\") +\n  labs(\n    title= \"Os 5 Idiomas mais Presentes nos Tweets do @vinijr\",\n       subtitle = \"Desconsiderando o Português\"\", x=\"\"\", \n       y ='Porcentagem (%)') +\n   theme(axis.ticks.x=element_blank(),\n          axis.text.y =element_blank())"
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#conclusão",
    "href": "posts/Twitter/API_Twitter.html#conclusão",
    "title": "Como usar API do Twitter",
    "section": "Conclusão",
    "text": "Conclusão\nEmbora eu tenha descartado a maioria das colunas, estou impressionado pelo volume de informação que a API disponibiliza para o usuário (43 colunas) um leque absurdo de análises que podem ser feitas. A parte mais complexa é estabelecer a conexão com a API mas uma vez feita basta se atentar no tempo de validade das chaves."
  },
  {
    "objectID": "posts/Twitter/API_Twitter.html#autenticando",
    "href": "posts/Twitter/API_Twitter.html#autenticando",
    "title": "Como usar API do Twitter",
    "section": "Autenticando",
    "text": "Autenticando\n\ntwitter_token = create_token()\nauth_as(twitter_token)"
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html",
    "href": "posts/Governos do Reino Unido/Web Scraping.html",
    "title": "Extraindo dados da wikipedia",
    "section": "",
    "text": "Venho me interessando pelo tema de raspagem de dados (Web Scraping) e resolvi trazer exemplo “simples” de como faze-lo. A ideia aqui é extrair os dados da página da Wikipédia, realizar o tratamento e fazer análise exploratória."
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#bibliotecas",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#bibliotecas",
    "title": "Extraindo dados da wikipedia",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(forcats)\nlibrary(ggalt)\nlibrary(treemap)\nlibrary(magrittr) # pipe\nlibrary(lubridate)# tratamento de datas\nlibrary(knitr) # formatação de tabelasas\nlibrary(rvest) # raspagem de dados"
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#carregando-os-dados",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#carregando-os-dados",
    "title": "Extraindo dados da wikipedia",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nPara carregar os dados é necessário o Link da página da wikipédia e a tag da tabela. Para fazer isso basta clicar com o botão direito próxima a tabela desejada e escolher a opção inspecionar elemento, em seguida identificar tag da tabela e copiar seu XPath como mostra a figura 1.\n\n\nFígura 1\n\n\nCom essas informações podemos fazer a extração.\n\nurl <- \"https://pt.wikipedia.org/wiki/Lista_de_primeiros-ministros_do_Reino_Unido\"\ntag <- '//*[@id=\"mw-content-text\"]/div[1]/table[3]'\n\ndados <- url %>%  \n  rvest::read_html() %>% \n  rvest::html_node(xpath = tag) %>%\n  rvest::html_table()\n\nPodemos verificar o tipo de estrutura.\n\nclass(dados)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nPodemos inspessionar os nomes das colunas e os tipos de dados que estão presentes.\n\ncolnames(dados)\n\n [1] \"N.º\"                                                \n [2] \"Primeiro-ministro (Nascimento–Falecimento)\"         \n [3] \"Primeiro-ministro (Nascimento–Falecimento)\"         \n [4] \"Mandato (Duração em anos e dias)\"                   \n [5] \"Mandato (Duração em anos e dias)\"                   \n [6] \"Partido\"                                            \n [7] \"Partido\"                                            \n [8] \"Cargos ministeriais ocupados como primeiro-ministro\"\n [9] \"Monarca (Reino)\"                                    \n[10] \"Ref.\"                                               \n\n\n\nglimpse(dados)\n\nRows: 188\nColumns: 10\n$ N.º                                                   <chr> \"1\", \"1\", \"1\", \"~\n$ `Primeiro-ministro (Nascimento–Falecimento)`          <chr> \"\", \"\", \"\", \"\", ~\n$ `Primeiro-ministro (Nascimento–Falecimento)`          <chr> \"Sir Robert Walp~\n$ `Mandato (Duração em anos e dias)`                    <chr> \"3 de abril de 1~\n$ `Mandato (Duração em anos e dias)`                    <chr> \"1722\", \"1727\", ~\n$ Partido                                               <chr> \"\", \"\", \"\", \"\", ~\n$ Partido                                               <chr> \"Whig\", \"Whig\", ~\n$ `Cargos ministeriais ocupados como primeiro-ministro` <chr> \"Chanceler do Te~\n$ `Monarca (Reino)`                                     <chr> \"Jorge I  (1714–~\n$ Ref.                                                  <chr> \"[20]\", \"[20]\", ~\n\n\nAqui termina a parte simples."
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html",
    "href": "posts/Copa do Mundo/Copa do Mundo.html",
    "title": "Usando R para acessar google sheet",
    "section": "",
    "text": "O (Bryan 2022) é um pacote que pode acessas dados de planilhas do google sheets via API. É interessante armazenar dados na nuvem, pois economiza memória e te permite acessa-los de outros locais de uma forma segura."
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html#bibliotecas",
    "href": "posts/Copa do Mundo/Copa do Mundo.html#bibliotecas",
    "title": "Usando R para acessar google sheet",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(googlesheets4)\n\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(purrr)\n\nlibrary(ggplot2)\nlibrary(ggbump)"
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html#autenticação",
    "href": "posts/Copa do Mundo/Copa do Mundo.html#autenticação",
    "title": "Usando R para acessar google sheet",
    "section": "Autenticação",
    "text": "Autenticação\nPrimeiro armazenar o link da planilha.\n\nurl_dados <- \"https://docs.google.com/spreadsheets/d/1urL93VWfy0R_hqNjNq-fdQdXF6Ta9L38k5wVuubL9Zw/edit#gid=659891394\"\n\nAo executar qualquer função desse pacote você será levado a seguinte página do seu Browser.\n\n\nEscolher um email para autênticação\n\n\nDar a permissão para editar, criar excluir dados da planilha.\n\n\nAutorização para a manipulação da planilha.\n\n\nApós a primeira autênticação as requisições passam ser autorizadas via console do RStudio.\nA função sheet_properties mostra quais são as planilhas que estão na pasta de trabalho.\n\nsheet_properties(url_dados)\n\n# A tibble: 25 x 8\n   name        index         id type  visible grid_rows grid_columns data  \n   <chr>       <int>      <int> <chr> <lgl>       <int>        <int> <list>\n 1 País            0          0 GRID  TRUE         1000           26 <NULL>\n 2 Copa_Final      1  739370969 GRID  TRUE         1000           26 <NULL>\n 3 Artilheiros     2  332312744 GRID  TRUE         1000           26 <NULL>\n 4 Disputas        3 1811446063 GRID  TRUE         1000           26 <NULL>\n 5 1930            4 1245394281 GRID  TRUE         1000           26 <NULL>\n 6 1934            5  199002872 GRID  TRUE         1000           26 <NULL>\n 7 1938            6  659891394 GRID  TRUE         1000           26 <NULL>\n 8 1950            7 1547033404 GRID  TRUE         1000           26 <NULL>\n 9 1954            8  946131332 GRID  TRUE         1000           26 <NULL>\n10 1958            9   35115059 GRID  TRUE         1000           26 <NULL>\n# ... with 15 more rows"
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html#manipulações",
    "href": "posts/Copa do Mundo/Copa do Mundo.html#manipulações",
    "title": "Usando R para acessar google sheet",
    "section": "Manipulações",
    "text": "Manipulações\nExiste conjunto de planilhas nesta base e podemos uni-las para criar uma tabela só.\n\nlista_de_copas  <-list(\"1930\",\"1934\",\"1938\",\"1950\",\"1954\",\n                       \"1958\",\"1962\",\"1966\",\"1970\",\"1974\",\n                       \"1978\",\"1982\",\"1986\",\"1990\",\"1994\",\n                       \"1998\",\"2002\",\"2006\",\"2010\",\"2014\",\n                       \"2018\")\n\ndf <-data.frame()\n\nfor(i in lista_de_copas){\n  \n  df <- rbind(df,read_sheet(url_dados,sheet = i))\n  \n  \n}\n\n\n\n\n\n\n\nTipo de Arquivo\n\n\n\n\n\nÉ comum confundir o tipo de extensão do arquivo. A biblioteca {googlesheet4} é para ler e manipular planilhas criadas utilizando google sheets e não planilhas xlsx (excel microsoft).\n\n\n\nVerificando o tipo de dado.\n\nglimpse(df)\n\nRows: 457\nColumns: 9\n$ Ano           <dbl> 1930, 1930, 1930, 1930, 1930, 1930, 1930, 1930, 1930, 19~\n$ Posição       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 2, 3, 4, 5~\n$ NumJogos      <chr> \"4\", \"5\", \"3\", \"3\", \"3\", \"2\", \"3\", \"2\", \"2\", \"2\", \"2\", \"~\n$ Vitórias      <dbl> 4, 4, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 4, 3, 3, 2, 1, 1,~\n$ Empates       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,~\n$ Derrotas      <dbl> 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 3, 0, 1, 1, 2, 1, 1,~\n$ `Gols Pro`    <dbl> 15, 18, 7, 7, 5, 5, 4, 3, 1, 1, 0, 0, 4, 12, 9, 11, 7, 4~\n$ `Gols Contra` <dbl> 3, 9, 6, 7, 3, 2, 3, 5, 3, 4, 4, 8, 13, 3, 6, 8, 7, 3, 4~\n$ Seleção       <chr> \"Uruguai\", \"Argentina\", \"Estados Unidos\", \"Sérvia\", \"Chi~\n\n\nQuem mais jogou?\n\ndf %>% group_by(Seleção) %>% \n  summarise(total_jogos = sum(as.numeric(NumJogos))) %>%\n  arrange(desc(total_jogos)) %>% \n  slice(1:5) %>% \n  ggplot(aes(x = Seleção, y= total_jogos,label =total_jogos)) +\n  geom_col(fill = \"#0b8d96\") +\n  geom_text(position = position_stack(vjust = 1.05),\n            color =\"#011112\")+\n  labs(title = \"Seleções que mais jogaram\",\n       subtitle = \"Dados agregados desde a copa de 1934\",\n       y = \"\",x =\"seleções\") +\n  theme(plot.title = element_text(face = \"bold\",size = 12),\n        plot.subtitle = element_text(face= \"italic\",size =10),\n        )\n\n\n\n\nDesempenho do Brasil.\n\ndf %>%filter(Seleção == \"Brasil\")%>% select(1:6) %>%   \n  tail() %>% \n  kable(caption = \"Desempenho do Brasil nas últimas copas\",\n        col.names = c(\"Ano\",\"Posição\",\"Número de Jogos\",\n                      \"Vitórias\",\"Empates\",\"Derrotas\"),\n        align = \"cccccc\")\n\n\nDesempenho do Brasil nas últimas copas\n\nAno\nPosição\nNúmero de Jogos\nVitórias\nEmpates\nDerrotas\n\n\n\n1998\n2\n7\n4\n1\n2\n\n\n2002\n1\n7\n7\n0\n0\n\n\n2006\n5\n5\n4\n0\n1\n\n\n2010\n6\n5\n3\n1\n1\n\n\n2014\n4\n7\n3\n2\n2\n\n\n2018\n6\n5\n3\n1\n1\n\n\n\n\n\nDesempenho das seleções campeãs de copa do mundo\n\ndf %<>% group_by(Seleção) %>% \n  mutate(campeao = if_else(Posição ==1,1,0),\n         Titulo_acumulado = purrr::accumulate(.x = campeao, \n                                    .f = ~ .x + .y))\n\n\ndf %>% filter(Titulo_acumulado !=0) %>% \n  ggplot(aes(Ano,Titulo_acumulado,color =Seleção))+\n  geom_bump(size =1.5) +\n  geom_point(size =3) +  \n  labs(title = \"Desempenho das Seleções\",\n       subtitle = \"1930-2018\",\n       x =\"Ano\",\n       y =\"Número de Títulos\") + \n  scale_x_continuous(breaks = seq(1930,2018,4)) +\n  theme(plot.title = element_text(face =\"bold\", size = 14),\n        plot.subtitle = element_text(face = \"italic\", size = 10,\n                        margin = margin(b = 0.5, unit = \"cm\")),\n        axis.text.y = element_text(face =\"bold\",size =10,\n                                    colour = \"#030202\"),\n        axis.text.x = element_text(face =\"bold\",size =10,\n                                    colour = \"#030202\",\n                                   angle = 90),\n        )\n\n\n\n\nTodas as seleções que venceram a copa do mundo fizeram mais gols?\n\nmaxGols <-df %>% group_by(Ano) %>% \n  summarise(nmaxgols = max(`Gols Pro`))\n\ncamp_edicao <- df %>% filter(Posição == 1)\n\nTexto <- paste(\n  strwrap(\"Número máximo de gols\",15),\n  collapse = \"\\n\")\n\n#Geralmente adoto um padrão os gráficos mas por algum motivo o ggplot não estava reconhecendo os nomes das colunas.\nggplot() +\n  geom_line(aes(x =maxGols$Ano,\n                y =maxGols$nmaxgols),\n            linetype = 1) +\n  scale_x_continuous(breaks = seq(1930,2018,4)) +\n  geom_point(aes(x=camp_edicao$Ano,\n                 y=camp_edicao$`Gols Pro`,\n                 color = camp_edicao$Seleção),\n             size = 2.1) +\n  scale_color_brewer(palette=\"Paired\") +\n  labs(title = \"Gols por Copa\",\n       subtitle = \"Seleções Campeãs de 1930 até 2018\",\n       x=\"Ano\",\n       y =\"Gols\",\n       color = \"Seleção Campeã\"\n       ) +\n   annotate(\"text\",x = 1938 ,y =23,size = 3,\n           label = Texto, fontface=\"bold\",colour=\"black\")+\n  theme(plot.title = element_text(face =\"bold\", size = 14),\n        plot.subtitle = element_text(face = \"italic\", size = 10,\n                        margin = margin(b = 0.5, unit = \"cm\")),\n        axis.text.y = element_text(face =\"bold\",size =10,\n                                    colour = \"#030202\"),\n        axis.text.x = element_text(angle = 90,\n                                   face =\"bold\",size =10,\n                                    colour = \"#030202\")) \n\n\n\n\nSinceramente eu não lembrava que a La Fúria (Seleção Espanhola) tinha marcado poucos gols em 2010 (Ano do Título), o time de Xavi e Iniesta era conhecido pela alta posse de bola e pela grande quantidade de passes, a Alemanha marcou o dobro de gols nesta edição."
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#tema",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#tema",
    "title": "Extraindo dados da wikipedia",
    "section": "Tema",
    "text": "Tema\nRecentemente houve a troca do primeiro ministro do Reino Unido a premiê Liz Truss, sendo destacada por ser a que ficou menos tempo no cargo, foi substituída por Rishi Sunak. Esse video da BBC conta um pouco de quem foi Liz Truss e como foi seu governo."
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#tratamento",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#tratamento",
    "title": "Extraindo dados da wikipedia",
    "section": "Tratamento",
    "text": "Tratamento\nNem sempre os dados estão estrurados do jeito que gostariámos (aliás quase nunca está). O Dataframe obtido está bagunçado então precisamos realizar uma “faxina”, padronizando as linhas e colunas.\n\n# |message: false\n# |warnings: false\ndados %>% head(3) %>% knitr::kable(caption = \"A Tabela Original\")\n\n\nA Tabela Original\n\n\n\n\n\n\n\n\n\n\n\n\n\nN.º\nPrimeiro-ministro (Nascimento–Falecimento)\nPrimeiro-ministro (Nascimento–Falecimento)\nMandato (Duração em anos e dias)\nMandato (Duração em anos e dias)\nPartido\nPartido\nCargos ministeriais ocupados como primeiro-ministro\nMonarca (Reino)\nRef.\n\n\n\n1\n\nSir Robert Walpole 1.º Conde de Orford (1676–1745)\n3 de abril de 1721 – 11 de fevereiro de 1742\n1722\n\nWhig\nChanceler do TesouroPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\nJorge I (1714–1727)\n[20]\n\n\n1\n\nSir Robert Walpole 1.º Conde de Orford (1676–1745)\n3 de abril de 1721 – 11 de fevereiro de 1742\n1727\n\nWhig\nChanceler do TesouroPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\nJorge II (1727–1760)\n[20]\n\n\n1\n\nSir Robert Walpole 1.º Conde de Orford (1676–1745)\n3 de abril de 1721 – 11 de fevereiro de 1742\n1734\n\nWhig\nChanceler do TesouroPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\nJorge II (1727–1760)\n[20]\n\n\n\n\n\nNão existe uma regra para realizar essa operação, a única certeza é que vai ser mais trabalhoso do que você pensou.\nO que me ajudou bastante foi desenhar e/ou imaginar a tabela final e fazer o simples mesmo que pareça preguiçoso, o importante é estar correto. Neste processo tem que ter paciência, pois uma operação equivocada (ou incompleta) pode ajudar a resolver um problema de um conjunto de linhas e simultaneamente prejudicar outro conjunto.\n\n\n\n\n\n\nAtenção ao volume de dados!\n\n\n\n\n\nSempre é importante verificar a tabela após cada operação, mas uma coisa é inspessionar um Dataframe de 100 linhas, é mais facíl monitorar os erros, outra é inspessionar um Dataframe de 50000 linhas. Então tenha cuidado e bom senso.\n\n\n\nO processo é literalmente um aprendizado, ao longo do caminho você já sabe o que precisa ser descartado (seja linhas ou colunas), as micro alterações (ajustes específicos), as macro alterações (as mais perigosas) e que operações cada coluna necessita. Esse processo te aproxima do resultado que você espera."
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#mão-na-massa",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#mão-na-massa",
    "title": "Extraindo dados da wikipedia",
    "section": "Mão na massa",
    "text": "Mão na massa\nExistem colunas com nomes idênticos mas informações diferentes.\n\n df <-dados %>% select(c(1,3,4,7,8)) %>% #selecionei as colunas de interesse \n rename(\n   c('ministro'='Primeiro-ministro (Nascimento–Falecimento)')'mandato'='Mandato (Duração em anos e dias)'as)',\n     'cargo' ='Cargos ministeriais ocupados como primeiro-ministro'))  %>%  #renomeando as colunas \n   filter(!grepl('dias',mandato)) %>% # eliminei as linhas que estão poluindo  \n   distinct() %>% # eliminei as linhas iguais\n   slice(-80) #eliminei a última linha manualmentee\n\nAgora quero colocar as datas em um formato em que o R interprete.\n\n#separando as colunas\ndf %<>% separate(mandato,\n                c(\"InicioMandato\",\"FimMandato\"),\n                sep =\"–\"“\",\n                convert = T,\n                remove = T,\n                )\n\n\n# | message: false\n# Separando as colunas para obter dia,mês e ano do início e fim de mandatoto\ndf %<>% separate(InicioMandato,\n                c(\"DiaIM\",\"MesIM\",\"AnoIM\"),\n                sep =\"de \",\n                remove = T)\ndf %<>% separate(FimMandato,\n                c(\"DiaFM\",\"MesFM\",\"AnoFM\"),\n                sep =\"de \",\n                remove = T)\n\nWarning: Expected 3 pieces. Missing pieces filled with `NA` in 1 rows [79].\n\n\n\n# obtendo um valor numérico dos mesess\ndf %<>% mutate(MesIM = case_when(\n  MesIM == \"janeiro \" ~ 1,\n  MesIM == \"fevereiro \" ~ 2,\n  MesIM == \"março \"\"~~33,\n  MesIM == \"abril \" ~ 4,\n  MesIM == \"maio \" ~ 5,\n  MesIM == \"junho \" ~ 6,\n  MesIM == \"julho \" ~ 7,\n  MesIM == \"agosto \" ~ 8,\n  MesIM == \"setembro \" ~ 9,\n  MesIM == \"outubro \" ~ 10,\n  MesIM == \"novembro \" ~ 11,\n  MesIM == \"dezembro \" ~ 12\n),\n  MesFM = case_when(\n  MesFM == \"janeiro \" ~ 1,\n  MesFM == \"fevereiro \" ~ 2,\n  MesFM == \"março \"\"~~33,\n  MesFM == \"abril \" ~ 4,\n  MesFM == \"maio \" ~ 5,\n  MesFM == \"junho \" ~ 6,\n  MesFM == \"julho \" ~ 7,\n  MesFM == \"agosto \" ~ 8,\n  MesFM == \"setembro \" ~ 9,\n  MesFM == \"outubro \" ~ 10,\n  MesFM == \"novembro \" ~ 11,\n  MesFM == \"dezembro \" ~ 12))\n\nÉ necessário uniformizar os dados, pois o espacinho em branco atrapalha as operações\n\ndf$AnoIM <- df$AnoIM %>% str_replace_all(\" \",\"\")\ndf$AnoFM <- df$AnoFM %>% str_replace_all(\" \",\"\")\n\nAgora podemos unir as colunas criadas para formar a data completa.\n\n# União das colunas  \ndf %<>% unite(\"Data_Inicio_Mandato\",\n             c(\"AnoIM\",\"MesIM\",\"DiaIM\"),\n             sep = \"/\") \ndf %<>% unite(\"Data_Fim_Mandato\",\n             c(\"AnoFM\",\"MesFM\",\"DiaFM\"),\n             sep = \"/\") \n# convertendo para o formato de datas\ndf$Data_Inicio_Mandato %<>%  as.Date() # convertendo\ndf$Data_Fim_Mandato %<>%  as.Date()\n\ndf$Data_Fim_Mandato[is.na(df$Data_Fim_Mandato)] <- now() # como o ministro ainda está em exercício colocamos o dia atual como último dia. a. \n\nCom o novo formato podemos obter a duração dos mandatos.\n\ndf %<>% mutate(duracao = df$Data_Fim_Mandato - df$Data_Inicio_Mandato)\n\nAqui estão as alterações simples e preguiçosas. São modificações tão específicas que é mais viável fazer a alteração manual do que buscar um método mais elaborado.\n\nNeste caso eram erros de ortografia e referências.\n\n\ndf$ministro[df$ministro == \"Sir Robert Walpole 1.º Conde de Orford (1676–1745)\"])<- \"Sir Robert Walpole 1.º Conde de Oxford (1676–1745)\"1745)\"\n\ndf$ministro[df$ministro ==  \"William Pitt, o Velho 1.º Conde de Chatham[a](1708–1778)\"])<-\"William Pitt, o Velho 1.º Conde de Chatham (1708–1778)\"1778)\"\n\ndf$ministro[df$ministro ==  \"(1) William Pitt, o Novo[b](1759–1806)\"]\"<-\"(1) William Pitt, o Novo (1759–1806)\"06)\"\n\ndf$ministro[df$ministro ==  \"(2) Benjamin Disraeli 1.º Conde de Beaconsfield[c](1804–1881)\"])<-\"(2) Benjamin Disraeli 1.º Conde de Beaconsfield (1804–1881)\"1881)\"\n\ndf$ministro[df$ministro ==  \"Alec Douglas-Home Barão Home de Hirsel[d](1894–1986)\"])<-\"Alec Douglas-Home Barão Home de Hirsel (1894–1986)\"1986)\"\n\nAgora com a tabela uniformizada podemos extrair um conjunto de caracteres utilizando expressões regulares (Regex). Neste caso queremos identificar e remover o padrão “(Ano de Nascimento - Ano de Falecimento)”\n\ndf$ministro <- df$ministro %>% str_replace_all(\"[(][0-9]{4}[–][0-9]{4}[)]|[(][0-9]{4}[)]\",\"\")\n\nFinalmente temos a tabela tratada.\n\ndf %>% head() %>% knitr::kable(caption = \"Tabela Tratada\")\n\n\nTabela Tratada\n\n\n\n\n\n\n\n\n\n\nN.º\nministro\nData_Inicio_Mandato\nData_Fim_Mandato\nPartido\ncargo\nduracao\n\n\n\n1\nSir Robert Walpole 1.º Conde de Oxford\n1721-04-03\n1742-02-11\nWhig\nChanceler do TesouroPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\n7619 days\n\n\n2\nSpencer Compton 1.º Conde de Wilmington\n1742-02-16\n1743-07-02\nWhig\nPrimeiro Lorde do Tesouro\n501 days\n\n\n3\nHenry Pelham\n1743-08-27\n1754-03-06\nWhig\nChanceler do TesouroPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\n3844 days\n\n\n4\n(1) Thomas Pelham-Holles 1.º Duque de Newcastle\n1754-03-16\n1756-11-11\nWhig\nPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\n971 days\n\n\n5\nWilliam Cavendish 4.º Duque de Devonshire\n1756-11-16\n1757-06-29\nWhig\nPrimeiro Lorde do TesouroLíder da Câmara dos ComunsLorde Alto Tesoureiro da Irlanda\n225 days\n\n\n6\n(2) Thomas Pelham-Holles 1.º Duque de Newcastle\n1757-06-29\n1762-05-26\nWhig\nPrimeiro Lorde do TesouroLíder da Câmara dos Comuns\n1792 days"
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#ver-também",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#ver-também",
    "title": "Extraindo dados da wikipedia",
    "section": "Ver também",
    "text": "Ver também\n\nBeatriz Milz\nCurso R"
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#visualizações",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#visualizações",
    "title": "Extraindo dados da wikipedia",
    "section": "Visualizações",
    "text": "Visualizações\nQuem passou mais tempo no cargo?\n\n# |message: false\n# |warnings: false\n\ntexto <- paste(\n  strwrap(\"Os 5 Primeiros-Ministros que permaneceram por mais tempo no cargo\",\n          30),\n  collapse = \"\\n\")\n\n\ndf %>% arrange(desc(duracao)) %>% \n  slice(1:5) %>% \n  ggplot(\n    aes(x = duracao,\n        y =ministro,\n        label = duracao)) +\n  geom_col(fill =\"#3c43c7\", size=0.05) + \n  geom_text(position = position_stack(vjust =1.05),\n            color=\"#030202\") +\n  \n  labs(title = texto,\n       subtitle = \"Duração em dias.\".\",\n       caption = \"(n) = contagem do mandato\",\n       y = \"\",\n       x =\"\" ) +\n    theme(axis.text.x = element_blank(),\n          axis.ticks.x=element_blank(),\n          axis.text.y =element_text(face =\"bold\",\n                                    colour = \"#030202\"))\n\nDon't know how to automatically pick scale for object of type difftime. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type difftime. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type difftime. Defaulting to continuous.\n\n\n\n\n\nEm que mês costuma terminar os mandatos?\n\ndf %>% group_by(mes = month(Data_Fim_Mandato, label = TRUE)) %>%   summarise(contagem =n()) %>% \n  ggplot(aes(x =mes,y =contagem, label = contagem ))+\n  geom_col(fill =\"#e05c09\") +\n  geom_text(vjust = 1.25) +\n  labs(title = \"Quantidade de términos de mandatos em cada mês\"s\",\n       subtitle = \"Desde 1742.\", y =\"\",x=\"\") +\n  theme(axis.text.y = element_blank(),\n        axis.ticks.y= element_blank(),\n        axis.text.x = element_text(face =\"bold\",size =8,\n                                    colour = \"#030202\"),\n        plot.title = element_text(face =\"bold\", size = 14),\n        plot.subtitle = element_text(face = \"italic\", size = 10,\n                        margin = margin(b = 0.5, unit = \"cm\")))\n\n\n\n\nÚltimos ministros que passarem pelo cargo.\n\ndf%>% filter(Data_Inicio_Mandato > \"2000-01-01\") %>% \n  mutate(\n    mandato_or = fct_reorder(ministro,Data_Inicio_Mandato))%>% \n  ggplot((aes(x=Data_Inicio_Mandato,xend = Data_Fim_Mandato,y = mandato_or))) +\n  geom_dumbbell(size =2.5,color=\"#cbcbd6\",colour_x =\"#3eb2f0\",\n                colour_xend = \"#0909ab\",dot_guide=TRUE,\n                dot_guide_size=0.25) +\n  labs(x =\"Ano\",y = \"\",title = \"Últimos Ministros\"\",\n       subtitle = \"A partir dos anos 2000\") +\n  theme(plot.title = element_text(face =\"bold\", size = 14),\n        plot.subtitle = element_text(face = \"italic\", size = 10,\n                        margin = margin(b = 0.5, unit = \"cm\")),\n        axis.text.y = element_text(face =\"bold\",size =10,\n                                    colour = \"#030202\"))\n\n\n\n\nQual partido mais governou?\n\ndf  %>% group_by(Partido) %>% \n  summarise(Tempo = as.numeric(sum(duracao))) %>% \n  treemap(index = c(\"Tempo\",\"Partido\"),vSize = \"Tempo\",\n          align.labels=\n            list(c(\"center\", \"center\"),c(\"center\", \"top\")),\n          title = \"Tempo, em Dias, que Cada Partido Governou\",\n          fontsize.labels=c(12,10),\n          palette = \"BrBG\") \n\n\n\n\n\n\n\n\n\n\nCuriosidade!\n\n\n\n\n\nAlguns partidos foram dissolvidos ou fundidos a outros partidos como por exemplo:\n\nTory ⟹ Partido Conservador\nWing ⟹ Partido Liberal"
  },
  {
    "objectID": "posts/Governos do Reino Unido/Web Scraping.html#sugestão",
    "href": "posts/Governos do Reino Unido/Web Scraping.html#sugestão",
    "title": "Extraindo dados da wikipedia",
    "section": "Sugestão",
    "text": "Sugestão\nUma boa ideia é extrair os títulos reais da coluna de ministros para realizar análises. Uma coluna que acabou não sendo utilizada é a de cargo, os cargos são strings que estão “coladas” uma na outra o desafio é separa-las"
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html#os-dados",
    "href": "posts/Copa do Mundo/Copa do Mundo.html#os-dados",
    "title": "Usando R para acessar google sheet",
    "section": "Os Dados",
    "text": "Os Dados\nOlhando o youtube me deparei com um evento gratuito de ensino de Power Bi e Excel com tema copa do mundo nada mais justo do que dar os devidos créditos, Leonardo - Power Bi Experience.\nA planilha (xlsx) foi baixada e convertida para uma google sheet (Explicado nesse tópico: Manipulações). É um conjunto de dados sobre a copa do mundo que traz o desempenho das seleções em cada edição, os artilheiros e detalhes das finais."
  },
  {
    "objectID": "posts/Copa do Mundo/Copa do Mundo.html#ver-também",
    "href": "posts/Copa do Mundo/Copa do Mundo.html#ver-também",
    "title": "Usando R para acessar google sheet",
    "section": "Ver também",
    "text": "Ver também\n\nBeatriz Milz"
  },
  {
    "objectID": "posts/Big Mac/Big Mac.html",
    "href": "posts/Big Mac/Big Mac.html",
    "title": "Poder de Compra e Big Mac",
    "section": "",
    "text": "A revista britânica The Economics em 1986 criou o índice Big Mac (ou Big Mac Index). Seu objetivo era comparar o poder de compra de cada país utilizando o preço de um big mac .\n\n\n\n\nO índice pode ser calculado pela seguinte fórmula:\n\\[\nÍndice\\,Big\\,Mac = \\frac{Preço\\, Big\\, Mac\\, no\\, país}{\nPreço\\, Big\\, Mac\\, no\\, EUA*taxa\\, de\\, câmbio }\\, -1\n\\]\nUm valor positivo significa que a moeda naquele momento está valorizada frente ao dólar americano, já um valor negativo indica que a moeda está subvalorizada. Os Estados Unidos da América recebe o valor de zero para seu índice, pois é a base de estudo.\n\n\n\n\n\n\nCuriosidade!!!\n\n\n\n\n\nNesse post a moeda estudada foi o Dólar Americano, entretanto já existe dados comparando as outras moedas como o Euro, Libra Esterlina, yuan chinês, e entre outras moedas.\n\n\n\nEsse índice permite também calcular a razão de troca ou paridade do poder de compra:\n\\[\nRazão\\,de\\,troca = \\frac{Preço\\,Big\\,Mac\\,no\\,país}{Preço\\,em\\, dolar}\n\\]\nGostaria de mostrar uma biblioteca que conheci recentemente ,(Arnold 2021), ela da uma embelezada no seus gráficos."
  },
 
  {
    "objectID": "posts/Big Mac/Big Mac.html#bibliotecas",
    "href": "posts/Big Mac/Big Mac.html#bibliotecas",
    "title": "Poder de Compra e Big Mac",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(dplyr) # tratamento de dados\nlibrary(knitr) # formatação de tabela\nlibrary(ggplot2) # gráficos\nlibrary(ggthemes) # temas de gráficos\nlibrary(lubridate) # tratamento de datas\nlibrary(glue) # colar textos"
  },
  {
    "objectID": "posts/Big Mac/Big Mac.html#carregando-os-dados",
    "href": "posts/Big Mac/Big Mac.html#carregando-os-dados",
    "title": "Poder de Compra e Big Mac",
    "section": "Carregando os dados",
    "text": "Carregando os dados\nOs dados podem ser encontrados no kaggle.\n\ndf <- read.csv(\"big_mac.csv\")\n\n\nglimpse(df)\n\nRows: 1,631\nColumns: 19\n$ date          <chr> \"2000-04-01\", \"2000-04-01\", \"2000-04-01\", \"2000-04-01\", …\n$ iso_a3        <chr> \"ARG\", \"AUS\", \"BRA\", \"CAN\", \"CHE\", \"CHL\", \"CHN\", \"CZE\", …\n$ currency_code <chr> \"ARS\", \"AUD\", \"BRL\", \"CAD\", \"CHF\", \"CLP\", \"CNY\", \"CZK\", …\n$ name          <chr> \"Argentina\", \"Australia\", \"Brazil\", \"Canada\", \"Switzerla…\n$ local_price   <dbl> 2.50, 2.59, 2.95, 2.85, 5.90, 1260.00, 9.90, 54.37, 24.7…\n$ dollar_ex     <dbl> 1.0000000, 1.6800000, 1.7900000, 1.4700000, 1.7000000, 5…\n$ dollar_price  <dbl> 2.500000, 1.541667, 1.648045, 1.938776, 3.470588, 2.4513…\n$ USD_raw       <dbl> 0.11607, -0.31176, -0.26427, -0.13448, 0.54937, 0.09436,…\n$ EUR_raw       <dbl> 0.05007, -0.35246, -0.30778, -0.18566, 0.45774, 0.02964,…\n$ GBP_raw       <dbl> -0.16722, -0.48645, -0.45102, -0.35417, 0.15609, -0.1834…\n$ JPY_raw       <dbl> -0.09864, -0.44416, -0.40581, -0.30099, 0.25130, -0.1161…\n$ CNY_raw       <dbl> 1.09091, 0.28939, 0.37836, 0.62152, 1.90267, 1.05023, 0.…\n$ GDP_bigmac    <dbl> 7803.329, 29144.877, 4822.739, 26087.329, 23872.716, 464…\n$ adj_price     <dbl> 1.922652, 2.301550, 1.869734, 2.247266, 2.207948, 1.8665…\n$ USD_adjusted  <dbl> 0.39117, -0.28335, -0.05696, -0.07698, 0.68172, 0.40514,…\n$ EUR_adjusted  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ GBP_adjusted  <dbl> -0.06626, -0.51898, -0.36704, -0.38047, 0.12876, -0.0568…\n$ JPY_adjusted  <dbl> 0.10096, -0.43285, -0.25369, -0.26953, 0.33090, 0.11201,…\n$ CNY_adjusted  <dbl> 0.97153, 0.01563, 0.33645, 0.30809, 1.38330, 0.99133, 0.…"
  },
  {
    "objectID": "posts/Eleição/eleicao_2022.html#bibliotecas",
    "href": "posts/Eleição/eleicao_2022.html#bibliotecas",
    "title": "Mapa Eleitoral",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\n#library(basedosdados)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(geobr)\n\n\ndf <- read.csv(\"dados.csv\")\n\ndados-tse-368314\nbasedosdados.br_tse_eleicoes.receitas_candidato\n# Defina o seu projeto no Google Cloud set_billing_id(“<YOUR_PROJECT_ID>”)"
  },
  {
    "objectID": "posts/Big Mac/Big Mac.html#no-mundo",
    "href": "posts/Big Mac/Big Mac.html#no-mundo",
    "title": "Poder de Compra e Big Mac",
    "section": "No Mundo",
    "text": "No Mundo\nAtualmente que países possuim um índice positivo, ou seja, que possuim uma moeda valorizada em relação ao dólar americano?\n\ndf |> filter(USD_raw > 0, date %in% max(date)) |>\n  ggplot(aes(x =reorder(name,USD_raw),y = USD_raw)) + \n  geom_col(fill = \"#236fa8\") +\n  labs(title = \"Países com moeda valorizada\",\n       subtitle = \"índices positivos em relação ao dólar em 01/07/2022\",\n       x = \"\",\n       y = \"índice Big Mac\",\n       caption = \"Mendes, Jorge L.,2023\") +\n  theme(\n    plot.title = element_text(face = \"bold\",size = 14),\n    axis.text.x = element_text(angle = 45)\n    \n  )\n\n\n\n\nQuais países possuem o menor índice?\n\ndf |> filter( date %in% max(date)) |>\n  arrange(desc(-USD_raw)) |> head() |> \n  ggplot(aes(x =reorder(name,USD_raw),y = USD_raw)) + \n  geom_col(fill = \"#db6d1f\") +\n  labs(title = \"Países com moeda subvalorizada\",\n       subtitle = \"índices positivos em relação ao dólar em 01/07/2022\",\n       x = \"\",\n       y = \"índice Big Mac\",\n       caption = \"Mendes, Jorge L.,2023\") +\n  theme(\n    plot.title = element_text(face = \"bold\",\n                              size = 14),\n    axis.text.x = element_text(angle = 45)\n    \n  )+\n  theme_solarized(base_size = 15, light = FALSE)"
  },
  {
    "objectID": "posts/Big Mac/Big Mac.html#situação-do-brasil.",
    "href": "posts/Big Mac/Big Mac.html#situação-do-brasil.",
    "title": "Poder de Compra e Big Mac",
    "section": "Situação do Brasil.",
    "text": "Situação do Brasil.\n\nBr <- df |>  filter(name == \"Brazil\")\n#últimas 5 linhas\nBr|> \n  tail() |>  \n  select(1,4:8) |> \n  knitr::kable(col.names = \n                 c(\"Data\",\"País\",\n                   \"Preço Local\",\"Razão de Troca\",\n                   \"Preço Dolar\",\"Índice(dólar)\"),\"pipe\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nData\nPaís\nPreço Local\nRazão de Troca\nPreço Dolar\nÍndice(dólar)\n\n\n\n32\n2020-01-14\nBrazil\n19.9\n4.14190\n4.804558\n-0.00320\n\n\n33\n2020-07-01\nBrazil\n20.9\n5.34045\n3.913528\n-0.18806\n\n\n34\n2021-01-01\nBrazil\n21.9\n5.50460\n3.978491\n-0.18640\n\n\n35\n2021-07-01\nBrazil\n22.9\n5.24865\n4.363027\n-0.11500\n\n\n36\n2022-01-01\nBrazil\n22.9\n5.31000\n4.312618\n-0.14432\n\n\n37\n2022-07-01\nBrazil\n22.9\n5.39175\n4.247230\n-0.17530\n\n\n\n\n\n\n#convertendo a coluna para data\nBr$date <- lubridate::as_date(Br$date)\n\nPodemos analisar a evolução temporal do preço.\n\nGrafico_base <- Br |> ggplot() +\n  geom_line(aes(x=date,y =local_price),\n            linewidth = 1.2,\n            color =\"#d10404\" ) +\n  \n  geom_line(aes(x=date,y = mean(local_price)),\n          linetype =2,\n          color ='#5c5a5a') +\n  geom_point(aes(x=max(date),y = max(local_price)),\n             color ='#d10404',\n             size = 3) \n\nMax_price <- Br |>  filter(date %in% max(date)) |> \n  mutate(label = glue::glue(\"R$ {round(local_price,2)}\"))\n\n\nGrafico_base +\n  \n  labs(y = 'Real',\n       x ='Ano',\n       title = \"Preço do Big Mac no Brasil\",\n       subtitle = \"2000-2022\",\n       caption = \"Mendes, Jorge L.,2023 \") +\n  \n  annotate('text',\n           x=min(Br$date),\n           y =13.2,\n           label = \"Média\",\n          colour = \"#5c5a5a\",\n          size = 3,\n          fontface = 'bold') +\n  \n  ggrepel::geom_text_repel(\n    data = Max_price,\n    aes(x = date,y = local_price,label = label),\n    size = 5,\n    color = \"#d10404\",\n    nudge_y = -5,\n    nudge_x = 0,\n    min.segment.length = 0) +\n  \n  \n  theme(\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_blank(),\n    plot.title = element_text(face = \"bold\",size = 14)) +\n  theme_economist()\n\n\n\n\nPodemos analizar o comportamento da razão de troca ao longo tempo.\n\nBr |> \n  ggplot(aes(x = date,y =dollar_ex)) + \n  geom_line(color = \"#218572\", linetype = 2, linewidth = 0.8) +\n  labs(title =\"Razão de troca\",\n       subtitle = \"Real Brasileiro/Dólar Americano 2000-2022\",\n       caption = \"Mendes, Jorge L,2023\",\n       x = \"Data\",\n       y = \"R$/$\") +\n  theme(\n    plot.title = element_text(face = \"bold\",size =14) \n  ) +\n  theme_economist_white()"
  },
  {
    "objectID": "posts/Big Mac/Big Mac.html#ver-também",
    "href": "posts/Big Mac/Big Mac.html#ver-também",
    "title": "Poder de Compra e Big Mac",
    "section": "Ver também",
    "text": "Ver também\n\nCurso R\nDicionário Financeiro\nTemas\nGGplot"
  },
  {
    "objectID": "posts/Otimização/Otimização.html",
    "href": "posts/Otimização/Otimização.html",
    "title": "Otimização",
    "section": "",
    "text": "Na engenharia obtemos várias soluções para um determinado problemas. O desafio é encontrar uma solução ótima considerando todas as restrições. Tudo depende do objetivo almejado, seja maximizando o lucro ou minimizando o custo de uma operação por exemplo.\n\nfonte: https://atemporaledesign.com.br\nO lpSolve é um software gratuito para resolução de programação linear, Linear/inteira e entre outras que possui funções disponibilizadas para linguagem R.\n\n\n\n\n\n\nProgramação\n\n\n\n\n\nNa área de otimização Programação se relaciona com o tipo de problema a ser resolvido. Ela é do tipo linear quando a função a ser otimizada e suas restrições são lineares. Já a Linear inteira é quando algumas ou todas as variáveis são inteiras.\nExistem também problemas de designação que lida com transporte.\n\n\n\nDocumentação"
  },
  {
    "objectID": "posts/Otimização/Otimização.html#problema",
    "href": "posts/Otimização/Otimização.html#problema",
    "title": "Otimização",
    "section": "Problema",
    "text": "Problema\nExemplo 15.1 do Chapra1.\n\n\n\n\nVariáveis:\n\\[\nx_1 \\Rightarrow Regular\n\\] \\[\nx_2 \\Rightarrow Premium\n\\]\nFunção objetivo:\n\\[\nMaximize\\, Z= 150  x_1 +\\, 175x_2\n\\]\nRestrições:\n\\[\n7x_1\\,+11x_2\\, \\leq 77\\,\\,\\,\\,(restrição\\,\\,de\\,\\,material)\n\\]\n\\[\n10x_1 \\,+8x_2\\,\\leq 80\\,\\,\\,\\,\\,(restrição\\,\\,de\\,\\,tempo)\n\\]\n\\[\nx_1 \\,\\leq 9\\,\\,\\,\\,\\,(restrição\\,\\,de\\,\\,armazenamento\\,\\,do\\,\\,tipo\\,\\,\"\nregular\")\n\\]\n\\[\nx_2 \\,\\leq 6\\,\\,\\,\\,\\,(restrição\\,\\,de\\,\\,armazenamento\\,\\,do\\,\\,tipo\\,\\,\"premium\")\n\\]\n\\[\nx_1,x_2\\, \\geq 0\\,\\,\\,\\,\\,(restrição\\,\\,de\\,\\,sinal)\n\\]"
  },
  {
    "objectID": "posts/Otimização/Otimização.html#formulação-do-problema",
    "href": "posts/Otimização/Otimização.html#formulação-do-problema",
    "title": "Otimização",
    "section": "Formulação do problema",
    "text": "Formulação do problema\nPara resolução do problema será utilizado a estrura de matrizes com os coeficientes das equações.\n\nf.obj <- c(150,175) # Coeficientes da função objetiva\n\nf.con <- matrix(\n  c(7,11,\n    10,8,\n    1,0,\n    0,1,\n    1,0,\n    0,1),\n  nrow=6, byrow=TRUE) # Coeficientes das equações de restrições\n\nf.dir <- c(\"<=\",\"<=\",\"<=\",\"<=\",\">=\",\">=\") #Direção das equações de restrições\nf.rhs <- c(77,80,9,6,0,0) # Valores das restrições\n\nmodelo <- lp(\"max\", f.obj, f.con, f.dir, f.rhs) \n\nDetalhes do problema:\n\npaste(\"Funão objetiva =\", modelo$objective[1],\"x1 +\",modelo$objective[2],\"x2\")\n\n[1] \"Funão objetiva = 150 x1 + 175 x2\"\n\n\nPodemos verificar o status do modelo.\n\nif (modelo$status == 0) {\n  paste(\"Foi encontrada uma solução viável\")\n}else{\n  paste(\"Não foi encontrada uma solução viável\") \n}\n\n[1] \"Foi encontrada uma solução viável\"\n\n\nA resposta é um valor numérico sendo 0 indica que foi encontrada uma solução viável e 2 indica que não foi encontrada uma solução viável.\nVerificar o objetivo da otimização:\n\nif (modelo$direction == 1) {\n  paste(\"maximizar a função\")\n}else{\n  paste(\"minimizar a função\")\n}\n\n[1] \"maximizar a função\"\n\n\nO valor da função maximizada:\n\npaste(\"O lucro máximo é \",round(modelo$objval,2),\"/semana\")\n\n[1] \"O lucro máximo é  1413.89 /semana\"\n\n\nA solução otimizada:\n\npaste(\"Gás Regular:\",round(modelo$solution[1],2),\"ton/semana\")\n\n[1] \"Gás Regular: 4.89 ton/semana\"\n\npaste(\"Gás Premium:\",round(modelo$solution[2],2),\"ton/semana\") \n\n[1] \"Gás Premium: 3.89 ton/semana\""
  },
  {
    "objectID": "posts/Otimização/Otimização.html#ver-também",
    "href": "posts/Otimização/Otimização.html#ver-também",
    "title": "Otimização",
    "section": "Ver também",
    "text": "Ver também\n\nSupply Chain Data Analytics"
  },
  {
    "objectID": "posts/Otimização/Otimização.html#bibliotecas",
    "href": "posts/Otimização/Otimização.html#bibliotecas",
    "title": "Otimização",
    "section": "Bibliotecas",
    "text": "Bibliotecas\n\nlibrary(lpSolve)"
  }
]